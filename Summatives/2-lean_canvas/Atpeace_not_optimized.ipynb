{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K32czIAzOuT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5N3sQ2kxx0NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import dependencies.\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "df = pd.read_csv('data/data_stress.csv')\n",
        "df.head(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "eu_FRPm-gzUq",
        "outputId": "ece5b0d4-552c-4ec1-ab19-c443c6e70035"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   snoring range  respiration rate  body temperature  limb movement  \\\n",
              "0          93.80            25.680            91.840         16.600   \n",
              "1          91.64            25.104            91.552         15.880   \n",
              "2          60.00            20.000            96.000         10.000   \n",
              "3          85.76            23.536            90.768         13.920   \n",
              "4          48.12            17.248            97.872          6.496   \n",
              "\n",
              "   blood oxygen   eye movement  hours of sleep  heart rate   Stress Levels  \n",
              "0         89.840         99.60           1.840        74.20              3  \n",
              "1         89.552         98.88           1.552        72.76              3  \n",
              "2         95.000         85.00           7.000        60.00              1  \n",
              "3         88.768         96.92           0.768        68.84              3  \n",
              "4         96.248         72.48           8.248        53.12              0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21628d54-29dc-467f-b3b5-c897ba25f5cc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>snoring range</th>\n",
              "      <th>respiration rate</th>\n",
              "      <th>body temperature</th>\n",
              "      <th>limb movement</th>\n",
              "      <th>blood oxygen</th>\n",
              "      <th>eye movement</th>\n",
              "      <th>hours of sleep</th>\n",
              "      <th>heart rate</th>\n",
              "      <th>Stress Levels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>93.80</td>\n",
              "      <td>25.680</td>\n",
              "      <td>91.840</td>\n",
              "      <td>16.600</td>\n",
              "      <td>89.840</td>\n",
              "      <td>99.60</td>\n",
              "      <td>1.840</td>\n",
              "      <td>74.20</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>91.64</td>\n",
              "      <td>25.104</td>\n",
              "      <td>91.552</td>\n",
              "      <td>15.880</td>\n",
              "      <td>89.552</td>\n",
              "      <td>98.88</td>\n",
              "      <td>1.552</td>\n",
              "      <td>72.76</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60.00</td>\n",
              "      <td>20.000</td>\n",
              "      <td>96.000</td>\n",
              "      <td>10.000</td>\n",
              "      <td>95.000</td>\n",
              "      <td>85.00</td>\n",
              "      <td>7.000</td>\n",
              "      <td>60.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>85.76</td>\n",
              "      <td>23.536</td>\n",
              "      <td>90.768</td>\n",
              "      <td>13.920</td>\n",
              "      <td>88.768</td>\n",
              "      <td>96.92</td>\n",
              "      <td>0.768</td>\n",
              "      <td>68.84</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>48.12</td>\n",
              "      <td>17.248</td>\n",
              "      <td>97.872</td>\n",
              "      <td>6.496</td>\n",
              "      <td>96.248</td>\n",
              "      <td>72.48</td>\n",
              "      <td>8.248</td>\n",
              "      <td>53.12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21628d54-29dc-467f-b3b5-c897ba25f5cc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-21628d54-29dc-467f-b3b5-c897ba25f5cc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-21628d54-29dc-467f-b3b5-c897ba25f5cc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-11510104-75a1-49d1-acd6-4a12e48115a4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11510104-75a1-49d1-acd6-4a12e48115a4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-11510104-75a1-49d1-acd6-4a12e48115a4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 630,\n  \"fields\": [\n    {\n      \"column\": \"snoring range\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19.372832993333716,\n        \"min\": 45.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 627,\n        \"samples\": [\n          59.76,\n          47.48,\n          49.04\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"respiration rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.336242163966984,\n        \"min\": 16.0,\n        \"max\": 48.56,\n        \"num_unique_values\": 626,\n        \"samples\": [\n          18.496,\n          20.384,\n          21.776\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.833369761239996,\n        \"min\": 85.0,\n        \"max\": 166.23,\n        \"num_unique_values\": 610,\n        \"samples\": [\n          94.784,\n          86.36,\n          86.92\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"limb movement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.001250266410543,\n        \"min\": 4.0,\n        \"max\": 46.8,\n        \"num_unique_values\": 614,\n        \"samples\": [\n          10.64,\n          9.008,\n          19.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"blood oxygen \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.891833304111071,\n        \"min\": 82.0,\n        \"max\": 154.3,\n        \"num_unique_values\": 622,\n        \"samples\": [\n          90.016,\n          93.92,\n          93.296\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eye movement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.480426498583038,\n        \"min\": 60.0,\n        \"max\": 185.36,\n        \"num_unique_values\": 608,\n        \"samples\": [\n          102.4,\n          91.72,\n          83.64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hours of sleep\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.341316405949159,\n        \"min\": 0.0,\n        \"max\": 20.22,\n        \"num_unique_values\": 491,\n        \"samples\": [\n          3.8,\n          5.88,\n          5.288\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"heart rate \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.260908076700092,\n        \"min\": 50.0,\n        \"max\": 158.65,\n        \"num_unique_values\": 603,\n        \"samples\": [\n          61.72,\n          66.76,\n          52.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stress Levels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# preparing the dataset\n",
        "target = 'Stress Levels'\n",
        "X = df.drop(target, axis=1)\n",
        "Y = df[target]\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "X.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "iJ7k9y5VWzIM",
        "outputId": "7503423a-feb1-410f-bbf9-591e637dba1c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    snoring range  respiration rate  body temperature  limb movement  \\\n",
              "0          93.800            25.680            91.840      16.600000   \n",
              "1          91.640            25.104            91.552      15.880000   \n",
              "2          60.000            20.000            96.000      10.000000   \n",
              "3          85.760            23.536            90.768      13.920000   \n",
              "4          48.120            17.248            97.872       6.496000   \n",
              "5          56.880            19.376            95.376       9.376000   \n",
              "6          47.000            16.800            97.200       5.600000   \n",
              "7          50.000            18.000            99.000       8.000000   \n",
              "8          45.280            16.112            96.168       4.224000   \n",
              "9          55.520            19.104            95.104       9.104000   \n",
              "10         73.440            21.344            93.344      11.344000   \n",
              "11         59.280            19.856            95.856       9.856000   \n",
              "12         48.600            17.440            98.160       6.880000   \n",
              "13         96.288            26.288            85.360      17.144000   \n",
              "14         87.800            24.080            91.040      14.600000   \n",
              "15         52.320            18.464            94.464       8.464000   \n",
              "16         52.640            18.528            94.528       8.528000   \n",
              "17         86.240            23.664            90.832      14.080000   \n",
              "18         81.560            22.416            90.208      12.520000   \n",
              "19         63.680            20.368            92.368      11.945188   \n",
              "\n",
              "    blood oxygen   eye movement  hours of sleep  heart rate   \n",
              "0        89.84000         99.60        1.840000    74.200000  \n",
              "1        89.55200         98.88        1.552000    72.760000  \n",
              "2        95.00000         85.00        7.000000    60.000000  \n",
              "3        88.76800         96.92        0.768000    68.840000  \n",
              "4        96.24800         72.48        8.248000    53.120000  \n",
              "5        94.06400         83.44        6.376000    58.440000  \n",
              "6        95.80000         68.00        7.800000    52.000000  \n",
              "7        97.00000         80.00        9.000000    55.000000  \n",
              "8        95.11200         61.12        7.112000    50.280000  \n",
              "9        93.65600         82.76        6.104000    57.760000  \n",
              "10       91.34400         91.72        4.016000    63.360000  \n",
              "11       94.78400         84.64        6.856000    59.640000  \n",
              "12       91.04792         74.40        8.440000    53.600000  \n",
              "13       82.43200        100.36        0.000000    75.720000  \n",
              "14       89.04000         97.60        1.040000    70.200000  \n",
              "15       92.69600         81.16        5.464000    56.160000  \n",
              "16       92.79200         81.32        3.835742    56.320000  \n",
              "17       88.83200         97.08        0.832000    69.160000  \n",
              "18       88.20800         95.52        0.208000    64.901733  \n",
              "19       90.36800         86.84        2.552000    60.920000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d3e2afd-6db5-45e9-a58c-bd4325a018b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>snoring range</th>\n",
              "      <th>respiration rate</th>\n",
              "      <th>body temperature</th>\n",
              "      <th>limb movement</th>\n",
              "      <th>blood oxygen</th>\n",
              "      <th>eye movement</th>\n",
              "      <th>hours of sleep</th>\n",
              "      <th>heart rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>93.800</td>\n",
              "      <td>25.680</td>\n",
              "      <td>91.840</td>\n",
              "      <td>16.600000</td>\n",
              "      <td>89.84000</td>\n",
              "      <td>99.60</td>\n",
              "      <td>1.840000</td>\n",
              "      <td>74.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>91.640</td>\n",
              "      <td>25.104</td>\n",
              "      <td>91.552</td>\n",
              "      <td>15.880000</td>\n",
              "      <td>89.55200</td>\n",
              "      <td>98.88</td>\n",
              "      <td>1.552000</td>\n",
              "      <td>72.760000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60.000</td>\n",
              "      <td>20.000</td>\n",
              "      <td>96.000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>95.00000</td>\n",
              "      <td>85.00</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>60.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>85.760</td>\n",
              "      <td>23.536</td>\n",
              "      <td>90.768</td>\n",
              "      <td>13.920000</td>\n",
              "      <td>88.76800</td>\n",
              "      <td>96.92</td>\n",
              "      <td>0.768000</td>\n",
              "      <td>68.840000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>48.120</td>\n",
              "      <td>17.248</td>\n",
              "      <td>97.872</td>\n",
              "      <td>6.496000</td>\n",
              "      <td>96.24800</td>\n",
              "      <td>72.48</td>\n",
              "      <td>8.248000</td>\n",
              "      <td>53.120000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>56.880</td>\n",
              "      <td>19.376</td>\n",
              "      <td>95.376</td>\n",
              "      <td>9.376000</td>\n",
              "      <td>94.06400</td>\n",
              "      <td>83.44</td>\n",
              "      <td>6.376000</td>\n",
              "      <td>58.440000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>47.000</td>\n",
              "      <td>16.800</td>\n",
              "      <td>97.200</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>95.80000</td>\n",
              "      <td>68.00</td>\n",
              "      <td>7.800000</td>\n",
              "      <td>52.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>50.000</td>\n",
              "      <td>18.000</td>\n",
              "      <td>99.000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>97.00000</td>\n",
              "      <td>80.00</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>55.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>45.280</td>\n",
              "      <td>16.112</td>\n",
              "      <td>96.168</td>\n",
              "      <td>4.224000</td>\n",
              "      <td>95.11200</td>\n",
              "      <td>61.12</td>\n",
              "      <td>7.112000</td>\n",
              "      <td>50.280000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>55.520</td>\n",
              "      <td>19.104</td>\n",
              "      <td>95.104</td>\n",
              "      <td>9.104000</td>\n",
              "      <td>93.65600</td>\n",
              "      <td>82.76</td>\n",
              "      <td>6.104000</td>\n",
              "      <td>57.760000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>73.440</td>\n",
              "      <td>21.344</td>\n",
              "      <td>93.344</td>\n",
              "      <td>11.344000</td>\n",
              "      <td>91.34400</td>\n",
              "      <td>91.72</td>\n",
              "      <td>4.016000</td>\n",
              "      <td>63.360000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>59.280</td>\n",
              "      <td>19.856</td>\n",
              "      <td>95.856</td>\n",
              "      <td>9.856000</td>\n",
              "      <td>94.78400</td>\n",
              "      <td>84.64</td>\n",
              "      <td>6.856000</td>\n",
              "      <td>59.640000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>48.600</td>\n",
              "      <td>17.440</td>\n",
              "      <td>98.160</td>\n",
              "      <td>6.880000</td>\n",
              "      <td>91.04792</td>\n",
              "      <td>74.40</td>\n",
              "      <td>8.440000</td>\n",
              "      <td>53.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>96.288</td>\n",
              "      <td>26.288</td>\n",
              "      <td>85.360</td>\n",
              "      <td>17.144000</td>\n",
              "      <td>82.43200</td>\n",
              "      <td>100.36</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>75.720000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>87.800</td>\n",
              "      <td>24.080</td>\n",
              "      <td>91.040</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>89.04000</td>\n",
              "      <td>97.60</td>\n",
              "      <td>1.040000</td>\n",
              "      <td>70.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>52.320</td>\n",
              "      <td>18.464</td>\n",
              "      <td>94.464</td>\n",
              "      <td>8.464000</td>\n",
              "      <td>92.69600</td>\n",
              "      <td>81.16</td>\n",
              "      <td>5.464000</td>\n",
              "      <td>56.160000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>52.640</td>\n",
              "      <td>18.528</td>\n",
              "      <td>94.528</td>\n",
              "      <td>8.528000</td>\n",
              "      <td>92.79200</td>\n",
              "      <td>81.32</td>\n",
              "      <td>3.835742</td>\n",
              "      <td>56.320000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>86.240</td>\n",
              "      <td>23.664</td>\n",
              "      <td>90.832</td>\n",
              "      <td>14.080000</td>\n",
              "      <td>88.83200</td>\n",
              "      <td>97.08</td>\n",
              "      <td>0.832000</td>\n",
              "      <td>69.160000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>81.560</td>\n",
              "      <td>22.416</td>\n",
              "      <td>90.208</td>\n",
              "      <td>12.520000</td>\n",
              "      <td>88.20800</td>\n",
              "      <td>95.52</td>\n",
              "      <td>0.208000</td>\n",
              "      <td>64.901733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>63.680</td>\n",
              "      <td>20.368</td>\n",
              "      <td>92.368</td>\n",
              "      <td>11.945188</td>\n",
              "      <td>90.36800</td>\n",
              "      <td>86.84</td>\n",
              "      <td>2.552000</td>\n",
              "      <td>60.920000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d3e2afd-6db5-45e9-a58c-bd4325a018b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3d3e2afd-6db5-45e9-a58c-bd4325a018b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3d3e2afd-6db5-45e9-a58c-bd4325a018b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-31c36e8b-e869-4f82-8662-ab759736497d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31c36e8b-e869-4f82-8662-ab759736497d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-31c36e8b-e869-4f82-8662-ab759736497d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 630,\n  \"fields\": [\n    {\n      \"column\": \"snoring range\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19.372832993333716,\n        \"min\": 45.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 627,\n        \"samples\": [\n          59.76,\n          47.48,\n          49.04\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"respiration rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.336242163966984,\n        \"min\": 16.0,\n        \"max\": 48.56,\n        \"num_unique_values\": 626,\n        \"samples\": [\n          18.496,\n          20.384,\n          21.776\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.745899022267411,\n        \"min\": 85.0,\n        \"max\": 166.23,\n        \"num_unique_values\": 611,\n        \"samples\": [\n          94.112,\n          95.872,\n          93.568\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"limb movement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.953313854086486,\n        \"min\": 4.0,\n        \"max\": 46.8,\n        \"num_unique_values\": 615,\n        \"samples\": [\n          13.16,\n          11.088,\n          8.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"blood oxygen \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.876254177589769,\n        \"min\": 82.0,\n        \"max\": 154.3,\n        \"num_unique_values\": 623,\n        \"samples\": [\n          83.872,\n          93.416,\n          92.768\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eye movement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.286142776599672,\n        \"min\": 60.0,\n        \"max\": 185.36,\n        \"num_unique_values\": 609,\n        \"samples\": [\n          77.44,\n          71.84,\n          67.84\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hours of sleep\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.3119709429966813,\n        \"min\": 0.0,\n        \"max\": 20.22,\n        \"num_unique_values\": 492,\n        \"samples\": [\n          4.28,\n          5.048,\n          1.648\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"heart rate \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.043984232497435,\n        \"min\": 50.0,\n        \"max\": 158.65,\n        \"num_unique_values\": 604,\n        \"samples\": [\n          72.04,\n          58.16,\n          52.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data set\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=10)\n",
        "\n",
        "num_classes = 5\n",
        "# Y_train = np.reshape(Y_train, (Y_train.shape[0], 1))\n",
        "# Y_test = np.reshape(Y_test, (Y_test.shape[0], 1))\n",
        "\n",
        "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEnK-Ddwl03h",
        "outputId": "6618c136-20b8-4268-b0de-81a1232e64ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((504, 8), (504,), (126, 8), (126,))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fix column names\n",
        "X_train = X_train.rename(columns={'blood oxygen ': 'blood oxygen', 'heart rate ': 'heart rate'})\n",
        "X_test = X_test.rename(columns={'blood oxygen ': 'blood oxygen', 'heart rate ': 'heart rate'})\n",
        "\n",
        "# Data preprocessing\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "Gb2fZ70ejZrV",
        "outputId": "3574b628-8529-4e81-d9e3-bc97f4fece64"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     snoring range  respiration rate  body temperature  limb movement  \\\n",
              "0           93.800            25.680            91.840         16.600   \n",
              "1           91.640            25.104            91.552         15.880   \n",
              "2           60.000            20.000            96.000         10.000   \n",
              "3           85.760            23.536            90.768         13.920   \n",
              "4           48.120            17.248            97.872          6.496   \n",
              "..             ...               ...               ...            ...   \n",
              "625         69.600            46.500            92.960         10.960   \n",
              "626         48.440            17.376            98.064          6.752   \n",
              "627         97.504            27.504            86.880         17.752   \n",
              "628         58.640            19.728            95.728          9.728   \n",
              "629         73.920            21.392            93.392         11.392   \n",
              "\n",
              "     blood oxygen   eye movement  hours of sleep  heart rate   \n",
              "0           89.840         99.60        1.840000        74.20  \n",
              "1           89.552         98.88        1.552000        72.76  \n",
              "2           95.000         85.00        7.000000        60.00  \n",
              "3           88.768         96.92        0.768000        68.84  \n",
              "4           96.248         72.48        8.248000        53.12  \n",
              "..             ...           ...             ...          ...  \n",
              "625         90.960         89.80        3.835742        62.40  \n",
              "626         96.376         73.76        8.376000        53.44  \n",
              "627         84.256        101.88        0.000000        78.76  \n",
              "628         94.592         84.32        6.728000        59.32  \n",
              "629         91.392         91.96        4.088000        63.48  \n",
              "\n",
              "[630 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7724df58-0f9e-4146-b941-e65e3d6642de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>snoring range</th>\n",
              "      <th>respiration rate</th>\n",
              "      <th>body temperature</th>\n",
              "      <th>limb movement</th>\n",
              "      <th>blood oxygen</th>\n",
              "      <th>eye movement</th>\n",
              "      <th>hours of sleep</th>\n",
              "      <th>heart rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>93.800</td>\n",
              "      <td>25.680</td>\n",
              "      <td>91.840</td>\n",
              "      <td>16.600</td>\n",
              "      <td>89.840</td>\n",
              "      <td>99.60</td>\n",
              "      <td>1.840000</td>\n",
              "      <td>74.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>91.640</td>\n",
              "      <td>25.104</td>\n",
              "      <td>91.552</td>\n",
              "      <td>15.880</td>\n",
              "      <td>89.552</td>\n",
              "      <td>98.88</td>\n",
              "      <td>1.552000</td>\n",
              "      <td>72.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60.000</td>\n",
              "      <td>20.000</td>\n",
              "      <td>96.000</td>\n",
              "      <td>10.000</td>\n",
              "      <td>95.000</td>\n",
              "      <td>85.00</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>60.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>85.760</td>\n",
              "      <td>23.536</td>\n",
              "      <td>90.768</td>\n",
              "      <td>13.920</td>\n",
              "      <td>88.768</td>\n",
              "      <td>96.92</td>\n",
              "      <td>0.768000</td>\n",
              "      <td>68.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>48.120</td>\n",
              "      <td>17.248</td>\n",
              "      <td>97.872</td>\n",
              "      <td>6.496</td>\n",
              "      <td>96.248</td>\n",
              "      <td>72.48</td>\n",
              "      <td>8.248000</td>\n",
              "      <td>53.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>69.600</td>\n",
              "      <td>46.500</td>\n",
              "      <td>92.960</td>\n",
              "      <td>10.960</td>\n",
              "      <td>90.960</td>\n",
              "      <td>89.80</td>\n",
              "      <td>3.835742</td>\n",
              "      <td>62.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>626</th>\n",
              "      <td>48.440</td>\n",
              "      <td>17.376</td>\n",
              "      <td>98.064</td>\n",
              "      <td>6.752</td>\n",
              "      <td>96.376</td>\n",
              "      <td>73.76</td>\n",
              "      <td>8.376000</td>\n",
              "      <td>53.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>627</th>\n",
              "      <td>97.504</td>\n",
              "      <td>27.504</td>\n",
              "      <td>86.880</td>\n",
              "      <td>17.752</td>\n",
              "      <td>84.256</td>\n",
              "      <td>101.88</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>58.640</td>\n",
              "      <td>19.728</td>\n",
              "      <td>95.728</td>\n",
              "      <td>9.728</td>\n",
              "      <td>94.592</td>\n",
              "      <td>84.32</td>\n",
              "      <td>6.728000</td>\n",
              "      <td>59.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629</th>\n",
              "      <td>73.920</td>\n",
              "      <td>21.392</td>\n",
              "      <td>93.392</td>\n",
              "      <td>11.392</td>\n",
              "      <td>91.392</td>\n",
              "      <td>91.96</td>\n",
              "      <td>4.088000</td>\n",
              "      <td>63.48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>630 rows  8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7724df58-0f9e-4146-b941-e65e3d6642de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7724df58-0f9e-4146-b941-e65e3d6642de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7724df58-0f9e-4146-b941-e65e3d6642de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-045cd5b0-4180-430a-8de0-97ee67211138\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-045cd5b0-4180-430a-8de0-97ee67211138')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-045cd5b0-4180-430a-8de0-97ee67211138 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ab844142-40d9-46d9-a630-d23a122505ad\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ab844142-40d9-46d9-a630-d23a122505ad button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 630,\n  \"fields\": [\n    {\n      \"column\": \"snoring range\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19.372832993333716,\n        \"min\": 45.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 627,\n        \"samples\": [\n          59.76,\n          47.48,\n          49.04\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"respiration rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.336242163966984,\n        \"min\": 16.0,\n        \"max\": 48.56,\n        \"num_unique_values\": 626,\n        \"samples\": [\n          18.496,\n          20.384,\n          21.776\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.745899022267411,\n        \"min\": 85.0,\n        \"max\": 166.23,\n        \"num_unique_values\": 611,\n        \"samples\": [\n          94.112,\n          95.872,\n          93.568\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"limb movement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.953313854086486,\n        \"min\": 4.0,\n        \"max\": 46.8,\n        \"num_unique_values\": 615,\n        \"samples\": [\n          13.16,\n          11.088,\n          8.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"blood oxygen \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.876254177589769,\n        \"min\": 82.0,\n        \"max\": 154.3,\n        \"num_unique_values\": 623,\n        \"samples\": [\n          83.872,\n          93.416,\n          92.768\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eye movement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.286142776599672,\n        \"min\": 60.0,\n        \"max\": 185.36,\n        \"num_unique_values\": 609,\n        \"samples\": [\n          77.44,\n          71.84,\n          67.84\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hours of sleep\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.3119709429966813,\n        \"min\": 0.0,\n        \"max\": 20.22,\n        \"num_unique_values\": 492,\n        \"samples\": [\n          4.28,\n          5.048,\n          1.648\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"heart rate \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.043984232497435,\n        \"min\": 50.0,\n        \"max\": 158.65,\n        \"num_unique_values\": 604,\n        \"samples\": [\n          72.04,\n          58.16,\n          52.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPXs9cNdo6AU",
        "outputId": "264f23f9-f581-4e49-b647-63e201486c8a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                576       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3877 (15.14 KB)\n",
            "Trainable params: 3877 (15.14 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "l18PfXRtTeNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fu8dEOt5rfGb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=1000, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "_, accuracy_train = model.evaluate(X_train, Y_train, verbose=0)\n",
        "_, accuracy_test = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Train Accuracy: {:.2f}% , Test Accuracy: {:.2f}% '.format(accuracy_train*100, accuracy_test*100))\n",
        "\n",
        "# plot training history\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Save the model\n",
        "model.save('stress_model.h5')\n",
        "print(\"Model saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HfLQS1ADt4lS",
        "outputId": "5e462f1d-ec66-4a5d-d33b-a9e337234474"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "16/16 [==============================] - 1s 18ms/step - loss: 2.3982 - accuracy: 0.4167 - val_loss: 1.0189 - val_accuracy: 0.5873\n",
            "Epoch 2/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8554 - accuracy: 0.7103 - val_loss: 1.0613 - val_accuracy: 0.5714\n",
            "Epoch 3/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8000 - accuracy: 0.6567 - val_loss: 0.5711 - val_accuracy: 0.7063\n",
            "Epoch 4/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6973 - accuracy: 0.7083 - val_loss: 0.5915 - val_accuracy: 0.6508\n",
            "Epoch 5/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6130 - accuracy: 0.7639 - val_loss: 0.3756 - val_accuracy: 0.9683\n",
            "Epoch 6/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5471 - accuracy: 0.7817 - val_loss: 0.3388 - val_accuracy: 0.9048\n",
            "Epoch 7/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.8452 - val_loss: 0.5095 - val_accuracy: 0.7778\n",
            "Epoch 8/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.8611 - val_loss: 0.5162 - val_accuracy: 0.7063\n",
            "Epoch 9/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.8313 - val_loss: 0.2574 - val_accuracy: 0.9524\n",
            "Epoch 10/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.9067 - val_loss: 0.2698 - val_accuracy: 0.9206\n",
            "Epoch 11/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2986 - accuracy: 0.8849 - val_loss: 0.4267 - val_accuracy: 0.8175\n",
            "Epoch 12/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3397 - accuracy: 0.8710 - val_loss: 0.1923 - val_accuracy: 0.9683\n",
            "Epoch 13/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2224 - accuracy: 0.9325 - val_loss: 0.2541 - val_accuracy: 0.9127\n",
            "Epoch 14/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2983 - accuracy: 0.8948 - val_loss: 0.4123 - val_accuracy: 0.8175\n",
            "Epoch 15/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2221 - accuracy: 0.9246 - val_loss: 0.2479 - val_accuracy: 0.8889\n",
            "Epoch 16/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.2285 - accuracy: 0.9226 - val_loss: 0.1942 - val_accuracy: 0.9444\n",
            "Epoch 17/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.1879 - accuracy: 0.9524 - val_loss: 0.1467 - val_accuracy: 0.9444\n",
            "Epoch 18/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.2862 - accuracy: 0.8909 - val_loss: 0.2915 - val_accuracy: 0.9206\n",
            "Epoch 19/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.1468 - accuracy: 0.9583 - val_loss: 0.2246 - val_accuracy: 0.9206\n",
            "Epoch 20/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2081 - accuracy: 0.9306 - val_loss: 0.1137 - val_accuracy: 0.9683\n",
            "Epoch 21/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.2389 - accuracy: 0.9167 - val_loss: 0.2527 - val_accuracy: 0.8968\n",
            "Epoch 22/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.1970 - accuracy: 0.9127 - val_loss: 0.1583 - val_accuracy: 0.9365\n",
            "Epoch 23/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0891 - accuracy: 0.9782 - val_loss: 0.2161 - val_accuracy: 0.9286\n",
            "Epoch 24/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1941 - accuracy: 0.9306 - val_loss: 0.0905 - val_accuracy: 0.9762\n",
            "Epoch 25/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0950 - accuracy: 0.9742 - val_loss: 0.0967 - val_accuracy: 0.9603\n",
            "Epoch 26/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.2016 - accuracy: 0.9365 - val_loss: 0.0870 - val_accuracy: 0.9683\n",
            "Epoch 27/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.1131 - accuracy: 0.9702 - val_loss: 0.1076 - val_accuracy: 0.9762\n",
            "Epoch 28/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0900 - accuracy: 0.9722 - val_loss: 0.1154 - val_accuracy: 0.9524\n",
            "Epoch 29/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.1358 - accuracy: 0.9504 - val_loss: 0.3837 - val_accuracy: 0.7302\n",
            "Epoch 30/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.1946 - accuracy: 0.9365 - val_loss: 0.0818 - val_accuracy: 0.9762\n",
            "Epoch 31/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0761 - accuracy: 0.9782 - val_loss: 0.3155 - val_accuracy: 0.8413\n",
            "Epoch 32/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.1083 - accuracy: 0.9583 - val_loss: 0.0886 - val_accuracy: 0.9524\n",
            "Epoch 33/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1261 - accuracy: 0.9563 - val_loss: 0.1472 - val_accuracy: 0.9603\n",
            "Epoch 34/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.1132 - accuracy: 0.9563 - val_loss: 0.3346 - val_accuracy: 0.8492\n",
            "Epoch 35/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0669 - accuracy: 0.9802 - val_loss: 0.0890 - val_accuracy: 0.9683\n",
            "Epoch 36/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0679 - accuracy: 0.9762 - val_loss: 0.0852 - val_accuracy: 0.9841\n",
            "Epoch 37/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0756 - accuracy: 0.9762 - val_loss: 0.0556 - val_accuracy: 0.9841\n",
            "Epoch 38/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.1674 - accuracy: 0.9563 - val_loss: 0.0907 - val_accuracy: 0.9603\n",
            "Epoch 39/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0505 - accuracy: 0.9841 - val_loss: 0.0536 - val_accuracy: 0.9762\n",
            "Epoch 40/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.1352 - accuracy: 0.9623 - val_loss: 0.0585 - val_accuracy: 0.9762\n",
            "Epoch 41/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0939 - accuracy: 0.9563 - val_loss: 0.1062 - val_accuracy: 0.9762\n",
            "Epoch 42/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0459 - accuracy: 0.9841 - val_loss: 0.0593 - val_accuracy: 0.9762\n",
            "Epoch 43/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.1613 - accuracy: 0.9405 - val_loss: 0.0711 - val_accuracy: 0.9683\n",
            "Epoch 44/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0280 - accuracy: 0.9940 - val_loss: 0.0517 - val_accuracy: 0.9841\n",
            "Epoch 45/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1045 - accuracy: 0.9643 - val_loss: 0.1466 - val_accuracy: 0.9286\n",
            "Epoch 46/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0349 - accuracy: 0.9881 - val_loss: 0.0557 - val_accuracy: 0.9841\n",
            "Epoch 47/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.9603 - val_loss: 0.0595 - val_accuracy: 0.9683\n",
            "Epoch 48/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9861 - val_loss: 0.1603 - val_accuracy: 0.9365\n",
            "Epoch 49/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9821 - val_loss: 0.0429 - val_accuracy: 0.9841\n",
            "Epoch 50/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9762 - val_loss: 0.2314 - val_accuracy: 0.9365\n",
            "Epoch 51/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.9802 - val_loss: 0.0437 - val_accuracy: 0.9841\n",
            "Epoch 52/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9861 - val_loss: 0.0665 - val_accuracy: 0.9683\n",
            "Epoch 53/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0904 - accuracy: 0.9683 - val_loss: 0.0921 - val_accuracy: 0.9365\n",
            "Epoch 54/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.1010 - val_accuracy: 0.9603\n",
            "Epoch 55/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.1064 - accuracy: 0.9504 - val_loss: 0.0375 - val_accuracy: 0.9841\n",
            "Epoch 56/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0218 - accuracy: 0.9980 - val_loss: 0.0361 - val_accuracy: 0.9841\n",
            "Epoch 57/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0641 - accuracy: 0.9643 - val_loss: 0.0741 - val_accuracy: 0.9683\n",
            "Epoch 58/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0231 - accuracy: 0.9940 - val_loss: 0.0466 - val_accuracy: 0.9841\n",
            "Epoch 59/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 0.9960 - val_loss: 0.0608 - val_accuracy: 0.9603\n",
            "Epoch 60/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1013 - accuracy: 0.9702 - val_loss: 0.0372 - val_accuracy: 0.9841\n",
            "Epoch 61/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0379 - val_accuracy: 0.9841\n",
            "Epoch 62/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1272 - accuracy: 0.9603 - val_loss: 0.0360 - val_accuracy: 0.9841\n",
            "Epoch 63/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9980 - val_loss: 0.0350 - val_accuracy: 0.9841\n",
            "Epoch 64/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.0331 - val_accuracy: 0.9841\n",
            "Epoch 65/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0528 - accuracy: 0.9782 - val_loss: 0.0436 - val_accuracy: 0.9921\n",
            "Epoch 66/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0270 - accuracy: 0.9921 - val_loss: 0.2718 - val_accuracy: 0.9127\n",
            "Epoch 67/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0920 - accuracy: 0.9623 - val_loss: 0.0598 - val_accuracy: 0.9921\n",
            "Epoch 68/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9980 - val_loss: 0.1128 - val_accuracy: 0.9206\n",
            "Epoch 69/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0485 - accuracy: 0.9802 - val_loss: 0.0267 - val_accuracy: 0.9841\n",
            "Epoch 70/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9861 - val_loss: 0.2708 - val_accuracy: 0.9365\n",
            "Epoch 71/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.9881 - val_loss: 0.0292 - val_accuracy: 0.9841\n",
            "Epoch 72/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 0.9921 - val_loss: 0.2974 - val_accuracy: 0.8889\n",
            "Epoch 73/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.9802 - val_loss: 0.0334 - val_accuracy: 0.9762\n",
            "Epoch 74/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 0.1716 - val_accuracy: 0.9444\n",
            "Epoch 75/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0721 - accuracy: 0.9683 - val_loss: 0.0257 - val_accuracy: 0.9841\n",
            "Epoch 76/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.0963 - val_accuracy: 0.9365\n",
            "Epoch 77/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.9782 - val_loss: 0.0303 - val_accuracy: 0.9841\n",
            "Epoch 78/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0218 - accuracy: 0.9921 - val_loss: 0.0240 - val_accuracy: 0.9841\n",
            "Epoch 79/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 0.0340 - val_accuracy: 0.9921\n",
            "Epoch 80/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0562 - accuracy: 0.9861 - val_loss: 0.0576 - val_accuracy: 0.9841\n",
            "Epoch 81/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0328 - val_accuracy: 0.9921\n",
            "Epoch 82/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0525 - accuracy: 0.9762 - val_loss: 0.0604 - val_accuracy: 0.9683\n",
            "Epoch 83/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9841\n",
            "Epoch 84/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9762\n",
            "Epoch 85/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0586 - accuracy: 0.9802 - val_loss: 0.0616 - val_accuracy: 0.9683\n",
            "Epoch 86/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9841\n",
            "Epoch 87/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9841\n",
            "Epoch 88/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0828 - accuracy: 0.9722 - val_loss: 0.0342 - val_accuracy: 0.9921\n",
            "Epoch 89/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0638 - val_accuracy: 0.9921\n",
            "Epoch 90/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 0.9762\n",
            "Epoch 91/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0990 - accuracy: 0.9762 - val_loss: 0.0359 - val_accuracy: 0.9921\n",
            "Epoch 92/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9841\n",
            "Epoch 93/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9881 - val_loss: 0.3171 - val_accuracy: 0.9127\n",
            "Epoch 94/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 0.0279 - val_accuracy: 0.9841\n",
            "Epoch 95/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9841\n",
            "Epoch 96/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.9802 - val_loss: 0.0300 - val_accuracy: 0.9762\n",
            "Epoch 97/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9960 - val_loss: 0.0324 - val_accuracy: 0.9841\n",
            "Epoch 98/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0341 - val_accuracy: 0.9841\n",
            "Epoch 99/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0443 - accuracy: 0.9841 - val_loss: 0.0269 - val_accuracy: 0.9921\n",
            "Epoch 100/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9524\n",
            "Epoch 101/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9940 - val_loss: 0.0335 - val_accuracy: 0.9762\n",
            "Epoch 102/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0615 - accuracy: 0.9623 - val_loss: 0.0520 - val_accuracy: 0.9841\n",
            "Epoch 103/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0396 - val_accuracy: 0.9921\n",
            "Epoch 104/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9524\n",
            "Epoch 105/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 0.0418 - val_accuracy: 0.9683\n",
            "Epoch 106/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0382 - accuracy: 0.9802 - val_loss: 0.0254 - val_accuracy: 0.9841\n",
            "Epoch 107/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 0.9841\n",
            "Epoch 108/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 0.9861 - val_loss: 0.0770 - val_accuracy: 0.9762\n",
            "Epoch 109/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9921 - val_loss: 0.0361 - val_accuracy: 0.9841\n",
            "Epoch 110/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9683\n",
            "Epoch 111/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.9881 - val_loss: 0.1206 - val_accuracy: 0.9603\n",
            "Epoch 112/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 0.0347 - val_accuracy: 0.9762\n",
            "Epoch 113/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.5935 - val_accuracy: 0.8413\n",
            "Epoch 114/1000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0559 - accuracy: 0.9881 - val_loss: 0.0330 - val_accuracy: 0.9841\n",
            "Epoch 115/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9762\n",
            "Epoch 116/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9841\n",
            "Epoch 117/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1162 - accuracy: 0.9841 - val_loss: 0.0483 - val_accuracy: 0.9841\n",
            "Epoch 118/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0360 - val_accuracy: 0.9762\n",
            "Epoch 119/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9683\n",
            "Epoch 120/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9762\n",
            "Epoch 121/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5373 - val_accuracy: 0.8651\n",
            "Epoch 122/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0830 - accuracy: 0.9742 - val_loss: 0.0462 - val_accuracy: 0.9683\n",
            "Epoch 123/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9762\n",
            "Epoch 124/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9762\n",
            "Epoch 125/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9901 - val_loss: 0.0357 - val_accuracy: 0.9841\n",
            "Epoch 126/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9683\n",
            "Epoch 127/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9881 - val_loss: 0.0344 - val_accuracy: 0.9762\n",
            "Epoch 128/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9762\n",
            "Epoch 129/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.0446 - val_accuracy: 0.9762\n",
            "Epoch 130/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9762\n",
            "Epoch 131/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 0.9861 - val_loss: 0.0657 - val_accuracy: 0.9683\n",
            "Epoch 132/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9762\n",
            "Epoch 133/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9683\n",
            "Epoch 134/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.9762 - val_loss: 0.0411 - val_accuracy: 0.9762\n",
            "Epoch 135/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7.2093e-04 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9841\n",
            "Epoch 136/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9683\n",
            "Epoch 137/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6.0484e-04 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9762\n",
            "Epoch 138/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9940 - val_loss: 0.0556 - val_accuracy: 0.9683\n",
            "Epoch 139/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9683\n",
            "Epoch 140/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9841\n",
            "Epoch 141/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0761 - accuracy: 0.9742 - val_loss: 0.0498 - val_accuracy: 0.9841\n",
            "Epoch 142/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7.1575e-04 - accuracy: 1.0000 - val_loss: 0.0565 - val_accuracy: 0.9762\n",
            "Epoch 143/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6.1572e-04 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 0.9762\n",
            "Epoch 144/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9762\n",
            "Epoch 145/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0762 - accuracy: 0.9762 - val_loss: 0.1002 - val_accuracy: 0.9683\n",
            "Epoch 146/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0481 - val_accuracy: 0.9841\n",
            "Epoch 147/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5.8507e-04 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9762\n",
            "Epoch 148/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.9116e-04 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9683\n",
            "Epoch 149/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.1051 - accuracy: 0.9683 - val_loss: 0.1531 - val_accuracy: 0.9683\n",
            "Epoch 150/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.0904 - val_accuracy: 0.9683\n",
            "Epoch 151/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7.6571e-04 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9683\n",
            "Epoch 152/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5.1442e-04 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9683\n",
            "Epoch 153/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.6132e-04 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9683\n",
            "Epoch 154/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0319 - accuracy: 0.9881 - val_loss: 0.0812 - val_accuracy: 0.9762\n",
            "Epoch 155/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4.3248e-04 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9762\n",
            "Epoch 156/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3.9368e-04 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9683\n",
            "Epoch 157/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9881 - val_loss: 0.3452 - val_accuracy: 0.9206\n",
            "Epoch 158/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9960 - val_loss: 0.1020 - val_accuracy: 0.9683\n",
            "Epoch 159/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5.0271e-04 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9683\n",
            "Epoch 160/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.2845e-04 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9762\n",
            "Epoch 161/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 0.9782 - val_loss: 0.0765 - val_accuracy: 0.9762\n",
            "Epoch 162/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 6.6810e-04 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9683\n",
            "Epoch 163/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4.8103e-04 - accuracy: 1.0000 - val_loss: 0.0728 - val_accuracy: 0.9683\n",
            "Epoch 164/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.1393e-04 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9762\n",
            "Epoch 165/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9960 - val_loss: 1.3101 - val_accuracy: 0.7698\n",
            "Epoch 166/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0484 - accuracy: 0.9821 - val_loss: 0.0764 - val_accuracy: 0.9683\n",
            "Epoch 167/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.3654e-04 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 0.9683\n",
            "Epoch 168/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.9353e-04 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 0.9683\n",
            "Epoch 169/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 0.9960 - val_loss: 0.1124 - val_accuracy: 0.9841\n",
            "Epoch 170/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0411 - accuracy: 0.9881 - val_loss: 0.0545 - val_accuracy: 0.9683\n",
            "Epoch 171/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.6087e-04 - accuracy: 1.0000 - val_loss: 0.0585 - val_accuracy: 0.9683\n",
            "Epoch 172/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.4517e-04 - accuracy: 1.0000 - val_loss: 0.0627 - val_accuracy: 0.9683\n",
            "Epoch 173/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7.0346e-04 - accuracy: 1.0000 - val_loss: 0.5904 - val_accuracy: 0.8968\n",
            "Epoch 174/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0435 - accuracy: 0.9921 - val_loss: 0.0486 - val_accuracy: 0.9841\n",
            "Epoch 175/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.4696e-04 - accuracy: 1.0000 - val_loss: 0.0583 - val_accuracy: 0.9683\n",
            "Epoch 176/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.9551e-04 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9683\n",
            "Epoch 177/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0848 - accuracy: 0.9742 - val_loss: 0.1724 - val_accuracy: 0.9603\n",
            "Epoch 178/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9960 - val_loss: 0.0821 - val_accuracy: 0.9683\n",
            "Epoch 179/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.3651e-04 - accuracy: 1.0000 - val_loss: 0.0838 - val_accuracy: 0.9683\n",
            "Epoch 180/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.6156e-04 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 0.9683\n",
            "Epoch 181/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.7307e-04 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9683\n",
            "Epoch 182/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.8795e-04 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9683\n",
            "Epoch 183/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0601 - accuracy: 0.9821 - val_loss: 0.0768 - val_accuracy: 0.9841\n",
            "Epoch 184/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.1844e-04 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 0.9762\n",
            "Epoch 185/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.9961e-04 - accuracy: 1.0000 - val_loss: 0.0714 - val_accuracy: 0.9683\n",
            "Epoch 186/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.6379e-04 - accuracy: 1.0000 - val_loss: 0.0957 - val_accuracy: 0.9683\n",
            "Epoch 187/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.7947e-04 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9683\n",
            "Epoch 188/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.9704e-04 - accuracy: 1.0000 - val_loss: 0.3617 - val_accuracy: 0.9444\n",
            "Epoch 189/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0592 - accuracy: 0.9861 - val_loss: 0.0658 - val_accuracy: 0.9762\n",
            "Epoch 190/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 2.6261e-04 - accuracy: 1.0000 - val_loss: 0.0648 - val_accuracy: 0.9683\n",
            "Epoch 191/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.6167e-04 - accuracy: 1.0000 - val_loss: 0.0712 - val_accuracy: 0.9683\n",
            "Epoch 192/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 3.8524e-04 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.9683\n",
            "Epoch 193/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0355 - accuracy: 0.9901 - val_loss: 0.0735 - val_accuracy: 0.9841\n",
            "Epoch 194/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.2200e-04 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9841\n",
            "Epoch 195/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.4402e-04 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9841\n",
            "Epoch 196/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.1992 - val_accuracy: 0.9444\n",
            "Epoch 197/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0105 - accuracy: 0.9980 - val_loss: 0.1135 - val_accuracy: 0.9762\n",
            "Epoch 198/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.4350e-04 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 0.9762\n",
            "Epoch 199/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 9.8154e-05 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9762\n",
            "Epoch 200/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 8.9140e-05 - accuracy: 1.0000 - val_loss: 0.0825 - val_accuracy: 0.9683\n",
            "Epoch 201/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0851 - accuracy: 0.9702 - val_loss: 0.1788 - val_accuracy: 0.9683\n",
            "Epoch 202/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1454 - val_accuracy: 0.9683\n",
            "Epoch 203/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.1453e-04 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9683\n",
            "Epoch 204/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.5747e-04 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9683\n",
            "Epoch 205/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.5866e-04 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 0.9683\n",
            "Epoch 206/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.1283e-04 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9762\n",
            "Epoch 207/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9881 - val_loss: 0.0973 - val_accuracy: 0.9683\n",
            "Epoch 208/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.6557e-04 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9683\n",
            "Epoch 209/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.7193e-04 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9683\n",
            "Epoch 210/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.5951e-04 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 0.9762\n",
            "Epoch 211/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0236 - accuracy: 0.9940 - val_loss: 1.0577 - val_accuracy: 0.7778\n",
            "Epoch 212/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0503 - accuracy: 0.9802 - val_loss: 0.0790 - val_accuracy: 0.9762\n",
            "Epoch 213/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.0986e-04 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9762\n",
            "Epoch 214/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.0433e-04 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9683\n",
            "Epoch 215/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.2531e-04 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 0.9683\n",
            "Epoch 216/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7.5148e-05 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9683\n",
            "Epoch 217/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8.4708e-05 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9683\n",
            "Epoch 218/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9861 - val_loss: 0.2311 - val_accuracy: 0.9683\n",
            "Epoch 219/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9980 - val_loss: 0.1746 - val_accuracy: 0.9762\n",
            "Epoch 220/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.2055e-04 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9683\n",
            "Epoch 221/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7.1543e-05 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9683\n",
            "Epoch 222/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5.3185e-05 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9683\n",
            "Epoch 223/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6.3339e-05 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9683\n",
            "Epoch 224/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9940 - val_loss: 0.1984 - val_accuracy: 0.9524\n",
            "Epoch 225/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9762\n",
            "Epoch 226/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.1552e-04 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 0.9762\n",
            "Epoch 227/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9.2892e-05 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9683\n",
            "Epoch 228/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8.7340e-05 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9683\n",
            "Epoch 229/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5.9918e-05 - accuracy: 1.0000 - val_loss: 0.1460 - val_accuracy: 0.9762\n",
            "Epoch 230/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0556 - accuracy: 0.9841 - val_loss: 0.2357 - val_accuracy: 0.9683\n",
            "Epoch 231/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9980 - val_loss: 0.1931 - val_accuracy: 0.9683\n",
            "Epoch 232/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.4194e-04 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9683\n",
            "Epoch 233/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7.4494e-05 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9683\n",
            "Epoch 234/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5.0314e-05 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9683\n",
            "Epoch 235/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.3019e-05 - accuracy: 1.0000 - val_loss: 0.1614 - val_accuracy: 0.9683\n",
            "Epoch 236/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9921 - val_loss: 0.1412 - val_accuracy: 0.9762\n",
            "Epoch 237/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.9753e-04 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9762\n",
            "Epoch 238/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 8.9631e-05 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9683\n",
            "Epoch 239/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5.9733e-05 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9683\n",
            "Epoch 240/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5.3742e-05 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9683\n",
            "Epoch 241/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9881 - val_loss: 0.1953 - val_accuracy: 0.9683\n",
            "Epoch 242/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 0.9980 - val_loss: 0.1747 - val_accuracy: 0.9841\n",
            "Epoch 243/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.1741e-04 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9762\n",
            "Epoch 244/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6.9042e-05 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9683\n",
            "Epoch 245/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5.1515e-05 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9683\n",
            "Epoch 246/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 6.0982e-05 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9683\n",
            "Epoch 247/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.6653e-05 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9683\n",
            "Epoch 248/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.1088 - accuracy: 0.9881 - val_loss: 0.1895 - val_accuracy: 0.9762\n",
            "Epoch 249/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4.2939e-04 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 0.9683\n",
            "Epoch 250/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.0591e-04 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9683\n",
            "Epoch 251/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6.9651e-05 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9683\n",
            "Epoch 252/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9901 - val_loss: 0.2526 - val_accuracy: 0.9603\n",
            "Epoch 253/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9683\n",
            "Epoch 254/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6.8740e-05 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9683\n",
            "Epoch 255/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5.0330e-05 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9683\n",
            "Epoch 256/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4.5285e-05 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9683\n",
            "Epoch 257/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4.9242e-05 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9683\n",
            "Epoch 258/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.4726e-05 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9762\n",
            "Epoch 259/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.9881 - val_loss: 0.1476 - val_accuracy: 0.9683\n",
            "Epoch 260/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.9899e-05 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9683\n",
            "Epoch 261/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.2449e-05 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 0.9683\n",
            "Epoch 262/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.8811e-05 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.9683\n",
            "Epoch 263/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2.6670e-05 - accuracy: 1.0000 - val_loss: 0.1671 - val_accuracy: 0.9683\n",
            "Epoch 264/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.7217e-05 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9683\n",
            "Epoch 265/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 0.9940 - val_loss: 0.1721 - val_accuracy: 0.9683\n",
            "Epoch 266/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.0588e-05 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9683\n",
            "Epoch 267/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.2295e-05 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9683\n",
            "Epoch 268/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2.1360e-05 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9683\n",
            "Epoch 269/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2.1528e-05 - accuracy: 1.0000 - val_loss: 0.1804 - val_accuracy: 0.9683\n",
            "Epoch 270/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2.7618e-05 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9683\n",
            "Epoch 271/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.4309e-05 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9683\n",
            "Epoch 272/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0503 - accuracy: 0.9940 - val_loss: 0.1533 - val_accuracy: 0.9762\n",
            "Epoch 273/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8.2750e-05 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9762\n",
            "Epoch 274/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5.1001e-05 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.9762\n",
            "Epoch 275/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3.1920e-05 - accuracy: 1.0000 - val_loss: 0.1685 - val_accuracy: 0.9683\n",
            "Epoch 276/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3.2939e-05 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9683\n",
            "Epoch 277/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.9841 - val_loss: 0.2565 - val_accuracy: 0.9603\n",
            "Epoch 278/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 0.9980 - val_loss: 0.0909 - val_accuracy: 0.9683\n",
            "Epoch 279/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8.5683e-05 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9683\n",
            "Epoch 280/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5.1790e-05 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9683\n",
            "Epoch 281/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.5486e-05 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9683\n",
            "Epoch 282/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2.7735e-05 - accuracy: 1.0000 - val_loss: 0.1409 - val_accuracy: 0.9683\n",
            "Epoch 283/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.3345e-05 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9683\n",
            "Epoch 284/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6890 - val_accuracy: 0.8571\n",
            "Epoch 285/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0682 - accuracy: 0.9861 - val_loss: 0.1424 - val_accuracy: 0.9683\n",
            "Epoch 286/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6.6671e-05 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9683\n",
            "Epoch 287/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.7356e-05 - accuracy: 1.0000 - val_loss: 0.1458 - val_accuracy: 0.9683\n",
            "Epoch 288/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3.0571e-05 - accuracy: 1.0000 - val_loss: 0.1485 - val_accuracy: 0.9683\n",
            "Epoch 289/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.2432e-05 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9683\n",
            "Epoch 290/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.9085e-05 - accuracy: 1.0000 - val_loss: 0.1554 - val_accuracy: 0.9683\n",
            "Epoch 291/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.5356e-05 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 0.9683\n",
            "Epoch 292/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.8953e-05 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 0.9683\n",
            "Epoch 293/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0555 - accuracy: 0.9861 - val_loss: 0.1086 - val_accuracy: 0.9683\n",
            "Epoch 294/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3.0376e-04 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 0.9762\n",
            "Epoch 295/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 6.6090e-05 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.9683\n",
            "Epoch 296/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.4136e-05 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9683\n",
            "Epoch 297/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.1839e-05 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9683\n",
            "Epoch 298/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.7847e-05 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9683\n",
            "Epoch 299/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9960 - val_loss: 0.2651 - val_accuracy: 0.9603\n",
            "Epoch 300/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.1135 - val_accuracy: 0.9762\n",
            "Epoch 301/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9.2208e-05 - accuracy: 1.0000 - val_loss: 0.1141 - val_accuracy: 0.9762\n",
            "Epoch 302/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.7545e-05 - accuracy: 1.0000 - val_loss: 0.1148 - val_accuracy: 0.9762\n",
            "Epoch 303/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3.1045e-05 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9683\n",
            "Epoch 304/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2.4397e-05 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9683\n",
            "Epoch 305/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2.1733e-05 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9683\n",
            "Epoch 306/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0949 - accuracy: 0.9821 - val_loss: 0.0867 - val_accuracy: 0.9841\n",
            "Epoch 307/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2.0168e-04 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9841\n",
            "Epoch 308/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 6.3180e-05 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9762\n",
            "Epoch 309/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.9391e-05 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9683\n",
            "Epoch 310/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.0734e-05 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9683\n",
            "Epoch 311/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2.7753e-05 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9683\n",
            "Epoch 312/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.5741e-05 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9683\n",
            "Epoch 313/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6.8231e-05 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9762\n",
            "Epoch 314/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3.4135e-05 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9683\n",
            "Epoch 315/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0851 - accuracy: 0.9881 - val_loss: 0.1503 - val_accuracy: 0.9762\n",
            "Epoch 316/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.0429e-04 - accuracy: 1.0000 - val_loss: 0.1485 - val_accuracy: 0.9762\n",
            "Epoch 317/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5.0878e-05 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9762\n",
            "Epoch 318/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.9044e-05 - accuracy: 1.0000 - val_loss: 0.1462 - val_accuracy: 0.9683\n",
            "Epoch 319/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.9316e-05 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9683\n",
            "Epoch 320/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.5539e-05 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9683\n",
            "Epoch 321/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.2872e-05 - accuracy: 1.0000 - val_loss: 0.1451 - val_accuracy: 0.9683\n",
            "Epoch 322/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9.7095e-04 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9524\n",
            "Epoch 323/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9841 - val_loss: 0.1059 - val_accuracy: 0.9762\n",
            "Epoch 324/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7.2592e-05 - accuracy: 1.0000 - val_loss: 0.1086 - val_accuracy: 0.9762\n",
            "Epoch 325/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3.1266e-05 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9762\n",
            "Epoch 326/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 2.2818e-05 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9762\n",
            "Epoch 327/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.9516e-05 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9762\n",
            "Epoch 328/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.4548e-05 - accuracy: 1.0000 - val_loss: 0.1262 - val_accuracy: 0.9683\n",
            "Epoch 329/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.7276e-05 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9683\n",
            "Epoch 330/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 9.9418e-06 - accuracy: 1.0000 - val_loss: 0.1642 - val_accuracy: 0.9683\n",
            "Epoch 331/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0942 - accuracy: 0.9841 - val_loss: 0.0809 - val_accuracy: 0.9841\n",
            "Epoch 332/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.4028e-04 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9841\n",
            "Epoch 333/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 5.5941e-05 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9762\n",
            "Epoch 334/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.1832e-05 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9762\n",
            "Epoch 335/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.8505e-05 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9762\n",
            "Epoch 336/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.3411e-05 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9683\n",
            "Epoch 337/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 9.7507e-06 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9683\n",
            "Epoch 338/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.1367e-05 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9683\n",
            "Epoch 339/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.0445e-05 - accuracy: 1.0000 - val_loss: 0.1297 - val_accuracy: 0.9683\n",
            "Epoch 340/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0487 - accuracy: 0.9861 - val_loss: 0.1261 - val_accuracy: 0.9683\n",
            "Epoch 341/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3.4663e-05 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9683\n",
            "Epoch 342/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.5464e-05 - accuracy: 1.0000 - val_loss: 0.1248 - val_accuracy: 0.9683\n",
            "Epoch 343/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.9046e-05 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9683\n",
            "Epoch 344/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.5877e-05 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9683\n",
            "Epoch 345/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.1332e-05 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 0.9683\n",
            "Epoch 346/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0138 - accuracy: 0.9921 - val_loss: 0.1315 - val_accuracy: 0.9683\n",
            "Epoch 347/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3.4239e-05 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9762\n",
            "Epoch 348/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.9052e-05 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9762\n",
            "Epoch 349/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.2013e-05 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9683\n",
            "Epoch 350/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 9.1583e-06 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9683\n",
            "Epoch 351/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 7.4500e-06 - accuracy: 1.0000 - val_loss: 0.1455 - val_accuracy: 0.9683\n",
            "Epoch 352/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 6.9042e-06 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9683\n",
            "Epoch 353/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9861 - val_loss: 0.1600 - val_accuracy: 0.9683\n",
            "Epoch 354/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 4.9693e-04 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9683\n",
            "Epoch 355/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.5761e-04 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9683\n",
            "Epoch 356/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.6169e-05 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 0.9683\n",
            "Epoch 357/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.6842e-05 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9683\n",
            "Epoch 358/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.5218e-05 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 0.9683\n",
            "Epoch 359/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 9.8783e-06 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9683\n",
            "Epoch 360/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7.4063e-06 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9683\n",
            "Epoch 361/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.9861 - val_loss: 0.1598 - val_accuracy: 0.9683\n",
            "Epoch 362/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.1152e-04 - accuracy: 1.0000 - val_loss: 0.1301 - val_accuracy: 0.9683\n",
            "Epoch 363/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5.0382e-05 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9683\n",
            "Epoch 364/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.1091e-05 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9683\n",
            "Epoch 365/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.9266e-05 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9683\n",
            "Epoch 366/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.0556e-05 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9683\n",
            "Epoch 367/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7.8920e-06 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9683\n",
            "Epoch 368/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6.3347e-06 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 0.9683\n",
            "Epoch 369/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6.5815e-06 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 0.9683\n",
            "Epoch 370/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7.6197e-06 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9683\n",
            "Epoch 371/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 0.9901 - val_loss: 0.2166 - val_accuracy: 0.9683\n",
            "Epoch 372/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.5205e-04 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.9683\n",
            "Epoch 373/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5.5312e-05 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9683\n",
            "Epoch 374/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3.6042e-05 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9683\n",
            "Epoch 375/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2.8498e-05 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9683\n",
            "Epoch 376/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.8953e-05 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9683\n",
            "Epoch 377/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0209 - accuracy: 0.9921 - val_loss: 0.1795 - val_accuracy: 0.9762\n",
            "Epoch 378/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.7145e-05 - accuracy: 1.0000 - val_loss: 0.1744 - val_accuracy: 0.9683\n",
            "Epoch 379/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.2374e-05 - accuracy: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9683\n",
            "Epoch 380/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9.5091e-06 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9683\n",
            "Epoch 381/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7.7990e-06 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9683\n",
            "Epoch 382/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6.4990e-06 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9683\n",
            "Epoch 383/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6.1832e-06 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9683\n",
            "Epoch 384/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.2439 - val_accuracy: 0.9683\n",
            "Epoch 385/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9980 - val_loss: 0.1393 - val_accuracy: 0.9683\n",
            "Epoch 386/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.8585e-05 - accuracy: 1.0000 - val_loss: 0.1457 - val_accuracy: 0.9683\n",
            "Epoch 387/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 9.2380e-06 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9683\n",
            "Epoch 388/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 6.3261e-06 - accuracy: 1.0000 - val_loss: 0.1365 - val_accuracy: 0.9683\n",
            "Epoch 389/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5.6254e-06 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9683\n",
            "Epoch 390/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0458 - accuracy: 0.9921 - val_loss: 0.1691 - val_accuracy: 0.9762\n",
            "Epoch 391/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6.3031e-05 - accuracy: 1.0000 - val_loss: 0.1636 - val_accuracy: 0.9762\n",
            "Epoch 392/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3.1342e-05 - accuracy: 1.0000 - val_loss: 0.1604 - val_accuracy: 0.9762\n",
            "Epoch 393/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.8920e-05 - accuracy: 1.0000 - val_loss: 0.1583 - val_accuracy: 0.9683\n",
            "Epoch 394/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.1525e-05 - accuracy: 1.0000 - val_loss: 0.1545 - val_accuracy: 0.9683\n",
            "Epoch 395/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7.2043e-06 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9683\n",
            "Epoch 396/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5.4320e-06 - accuracy: 1.0000 - val_loss: 0.1513 - val_accuracy: 0.9683\n",
            "Epoch 397/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4.5030e-06 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9683\n",
            "Epoch 398/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0514 - accuracy: 0.9861 - val_loss: 0.1239 - val_accuracy: 0.9762\n",
            "Epoch 399/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5.1589e-05 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9762\n",
            "Epoch 400/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.3000e-05 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9762\n",
            "Epoch 401/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.8818e-05 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 0.9683\n",
            "Epoch 402/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9.5719e-06 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9683\n",
            "Epoch 403/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5.2378e-06 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9683\n",
            "Epoch 404/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.5501e-06 - accuracy: 1.0000 - val_loss: 0.1265 - val_accuracy: 0.9683\n",
            "Epoch 405/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.1076e-06 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.9683\n",
            "Epoch 406/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2.6721e-06 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 0.9683\n",
            "Epoch 407/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.6562e-06 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9683\n",
            "Epoch 408/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0299 - accuracy: 0.9960 - val_loss: 0.1216 - val_accuracy: 0.9762\n",
            "Epoch 409/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7.7047e-05 - accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 0.9762\n",
            "Epoch 410/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.7451e-05 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9762\n",
            "Epoch 411/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4435e-05 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 0.9762\n",
            "Epoch 412/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7.2165e-06 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 0.9762\n",
            "Epoch 413/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.3540e-06 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9762\n",
            "Epoch 414/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.2297e-06 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 0.9762\n",
            "Epoch 415/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3.3821e-06 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9683\n",
            "Epoch 416/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6.9170e-06 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9762\n",
            "Epoch 417/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0422 - accuracy: 0.9960 - val_loss: 0.1141 - val_accuracy: 0.9762\n",
            "Epoch 418/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9.6420e-05 - accuracy: 1.0000 - val_loss: 0.1146 - val_accuracy: 0.9762\n",
            "Epoch 419/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5.2572e-06 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9762\n",
            "Epoch 420/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.7379e-06 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9762\n",
            "Epoch 421/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.8310e-06 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9762\n",
            "Epoch 422/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.4165e-06 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.9762\n",
            "Epoch 423/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0818 - accuracy: 0.9821 - val_loss: 0.1790 - val_accuracy: 0.9762\n",
            "Epoch 424/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.6178e-04 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9762\n",
            "Epoch 425/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5.8743e-05 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9762\n",
            "Epoch 426/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.5096e-05 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9762\n",
            "Epoch 427/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.6402e-05 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9762\n",
            "Epoch 428/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.0118e-05 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 0.9762\n",
            "Epoch 429/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5.5257e-06 - accuracy: 1.0000 - val_loss: 0.1487 - val_accuracy: 0.9762\n",
            "Epoch 430/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.4241e-06 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9762\n",
            "Epoch 431/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.0222e-06 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9683\n",
            "Epoch 432/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1567 - accuracy: 0.9861 - val_loss: 0.1071 - val_accuracy: 0.9762\n",
            "Epoch 433/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 4.9735e-05 - accuracy: 1.0000 - val_loss: 0.1066 - val_accuracy: 0.9762\n",
            "Epoch 434/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.7521e-05 - accuracy: 1.0000 - val_loss: 0.1109 - val_accuracy: 0.9683\n",
            "Epoch 435/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9.0757e-06 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9683\n",
            "Epoch 436/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6.0658e-06 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9683\n",
            "Epoch 437/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.7080e-06 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9683\n",
            "Epoch 438/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5.2380e-06 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9683\n",
            "Epoch 439/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7.3634e-06 - accuracy: 1.0000 - val_loss: 0.1470 - val_accuracy: 0.9683\n",
            "Epoch 440/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 5.5849e-06 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9683\n",
            "Epoch 441/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4.3408e-06 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9683\n",
            "Epoch 442/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4.9518e-06 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9762\n",
            "Epoch 443/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0899 - accuracy: 0.9881 - val_loss: 0.0897 - val_accuracy: 0.9762\n",
            "Epoch 444/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.0364e-04 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9762\n",
            "Epoch 445/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7.8480e-05 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9762\n",
            "Epoch 446/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.3580e-05 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9762\n",
            "Epoch 447/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.6351e-05 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9762\n",
            "Epoch 448/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8.5490e-06 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9762\n",
            "Epoch 449/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5.5420e-06 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9762\n",
            "Epoch 450/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.7116e-06 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9683\n",
            "Epoch 451/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.6811e-06 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9683\n",
            "Epoch 452/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0889 - accuracy: 0.9881 - val_loss: 0.1448 - val_accuracy: 0.9762\n",
            "Epoch 453/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 0.9683\n",
            "Epoch 454/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.8345e-05 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9683\n",
            "Epoch 455/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.2723e-05 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9683\n",
            "Epoch 456/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8.4637e-06 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 0.9683\n",
            "Epoch 457/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5.3258e-06 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9683\n",
            "Epoch 458/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.4014e-06 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9683\n",
            "Epoch 459/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2.9127e-06 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9683\n",
            "Epoch 460/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.9859e-06 - accuracy: 1.0000 - val_loss: 0.1749 - val_accuracy: 0.9683\n",
            "Epoch 461/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.1509e-06 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 0.9683\n",
            "Epoch 462/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6.1772e-06 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 0.9683\n",
            "Epoch 463/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.9146e-06 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9683\n",
            "Epoch 464/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9960 - val_loss: 1.1128 - val_accuracy: 0.7698\n",
            "Epoch 465/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0264 - accuracy: 0.9921 - val_loss: 0.1275 - val_accuracy: 0.9683\n",
            "Epoch 466/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.2613e-05 - accuracy: 1.0000 - val_loss: 0.1419 - val_accuracy: 0.9683\n",
            "Epoch 467/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4259e-05 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9683\n",
            "Epoch 468/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7.8970e-06 - accuracy: 1.0000 - val_loss: 0.1571 - val_accuracy: 0.9683\n",
            "Epoch 469/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4.7689e-06 - accuracy: 1.0000 - val_loss: 0.1631 - val_accuracy: 0.9683\n",
            "Epoch 470/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.4156e-06 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9683\n",
            "Epoch 471/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.2488e-06 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 0.9683\n",
            "Epoch 472/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.5859e-06 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9683\n",
            "Epoch 473/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3.8170e-06 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9683\n",
            "Epoch 474/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.5334e-06 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9683\n",
            "Epoch 475/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.4718e-06 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9683\n",
            "Epoch 476/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.7221e-06 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9683\n",
            "Epoch 477/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0342 - accuracy: 0.9940 - val_loss: 0.1938 - val_accuracy: 0.9683\n",
            "Epoch 478/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 4.6166e-04 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9683\n",
            "Epoch 479/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 4.6332e-06 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9683\n",
            "Epoch 480/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.7513e-06 - accuracy: 1.0000 - val_loss: 0.1556 - val_accuracy: 0.9683\n",
            "Epoch 481/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.2326e-06 - accuracy: 1.0000 - val_loss: 0.1552 - val_accuracy: 0.9683\n",
            "Epoch 482/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 2.5559e-06 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9683\n",
            "Epoch 483/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.9001e-06 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9683\n",
            "Epoch 484/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.5031e-06 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9683\n",
            "Epoch 485/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.3401e-06 - accuracy: 1.0000 - val_loss: 0.1604 - val_accuracy: 0.9683\n",
            "Epoch 486/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.8720e-06 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9683\n",
            "Epoch 487/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0185 - accuracy: 0.9960 - val_loss: 0.1634 - val_accuracy: 0.9762\n",
            "Epoch 488/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 4.0807e-05 - accuracy: 1.0000 - val_loss: 0.1673 - val_accuracy: 0.9683\n",
            "Epoch 489/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 9.4412e-06 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9683\n",
            "Epoch 490/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 5.4173e-06 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9683\n",
            "Epoch 491/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 2.7762e-06 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 0.9683\n",
            "Epoch 492/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.0825e-06 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9683\n",
            "Epoch 493/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.6081e-06 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9683\n",
            "Epoch 494/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.5795e-06 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9683\n",
            "Epoch 495/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 2.4055e-06 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 0.9683\n",
            "Epoch 496/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 2.1267e-06 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9683\n",
            "Epoch 497/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.3174e-06 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9762\n",
            "Epoch 498/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0877 - accuracy: 0.9901 - val_loss: 0.1732 - val_accuracy: 0.9683\n",
            "Epoch 499/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 8.5257e-05 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 0.9683\n",
            "Epoch 500/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 2.7703e-05 - accuracy: 1.0000 - val_loss: 0.1788 - val_accuracy: 0.9683\n",
            "Epoch 501/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.2741e-05 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9683\n",
            "Epoch 502/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 6.7824e-06 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9683\n",
            "Epoch 503/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 4.0180e-06 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 0.9683\n",
            "Epoch 504/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 2.3131e-06 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 0.9683\n",
            "Epoch 505/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.8136e-06 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 0.9683\n",
            "Epoch 506/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.6755e-06 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 0.9683\n",
            "Epoch 507/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.7625e-06 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 0.9683\n",
            "Epoch 508/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.8699e-06 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9683\n",
            "Epoch 509/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0559 - accuracy: 0.9881 - val_loss: 0.1853 - val_accuracy: 0.9683\n",
            "Epoch 510/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 5.6890e-06 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 0.9683\n",
            "Epoch 511/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 4.1085e-06 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9683\n",
            "Epoch 512/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4.0908e-06 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 0.9683\n",
            "Epoch 513/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.0688e-06 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9683\n",
            "Epoch 514/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.7900e-06 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 0.9683\n",
            "Epoch 515/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.6883e-06 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9683\n",
            "Epoch 516/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.7394e-06 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9683\n",
            "Epoch 517/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.6807e-06 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 0.9683\n",
            "Epoch 518/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.8649e-06 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9683\n",
            "Epoch 519/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.7065e-06 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9683\n",
            "Epoch 520/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.0684e-06 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9683\n",
            "Epoch 521/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4099e-06 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9683\n",
            "Epoch 522/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.2261e-06 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9683\n",
            "Epoch 523/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.5187e-06 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9683\n",
            "Epoch 524/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0637 - accuracy: 0.9901 - val_loss: 0.1802 - val_accuracy: 0.9762\n",
            "Epoch 525/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 9.6091e-05 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 0.9762\n",
            "Epoch 526/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.8437e-05 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.9762\n",
            "Epoch 527/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.0440e-05 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 0.9683\n",
            "Epoch 528/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6.5254e-06 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9683\n",
            "Epoch 529/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.1800e-06 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9683\n",
            "Epoch 530/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.9982e-06 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9683\n",
            "Epoch 531/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.2232e-06 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9683\n",
            "Epoch 532/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.3997e-06 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9683\n",
            "Epoch 533/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.7542e-06 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9683\n",
            "Epoch 534/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.6438e-06 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9683\n",
            "Epoch 535/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.0057e-06 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9683\n",
            "Epoch 536/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0217 - accuracy: 0.9861 - val_loss: 0.1377 - val_accuracy: 0.9841\n",
            "Epoch 537/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.0527e-04 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 0.9762\n",
            "Epoch 538/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.8156e-05 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9762\n",
            "Epoch 539/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.7303e-05 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 0.9762\n",
            "Epoch 540/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.0987e-05 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9762\n",
            "Epoch 541/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5.6103e-06 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 0.9762\n",
            "Epoch 542/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.3984e-06 - accuracy: 1.0000 - val_loss: 0.1464 - val_accuracy: 0.9762\n",
            "Epoch 543/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.3713e-06 - accuracy: 1.0000 - val_loss: 0.1521 - val_accuracy: 0.9683\n",
            "Epoch 544/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.9856e-06 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.9683\n",
            "Epoch 545/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.5192e-06 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9683\n",
            "Epoch 546/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.8311e-06 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9683\n",
            "Epoch 547/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 9.9931e-07 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9683\n",
            "Epoch 548/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.0115e-06 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9683\n",
            "Epoch 549/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3.2434e-05 - accuracy: 1.0000 - val_loss: 0.4652 - val_accuracy: 0.9444\n",
            "Epoch 550/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9881 - val_loss: 0.1552 - val_accuracy: 0.9683\n",
            "Epoch 551/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.7233e-04 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9683\n",
            "Epoch 552/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2.3630e-05 - accuracy: 1.0000 - val_loss: 0.1494 - val_accuracy: 0.9683\n",
            "Epoch 553/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.1182e-05 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9683\n",
            "Epoch 554/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5.8765e-06 - accuracy: 1.0000 - val_loss: 0.1632 - val_accuracy: 0.9683\n",
            "Epoch 555/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.8139e-06 - accuracy: 1.0000 - val_loss: 0.1719 - val_accuracy: 0.9683\n",
            "Epoch 556/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.2556e-06 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9683\n",
            "Epoch 557/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.7505e-06 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9683\n",
            "Epoch 558/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3.1161e-06 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9683\n",
            "Epoch 559/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0917 - accuracy: 0.9802 - val_loss: 0.3192 - val_accuracy: 0.9683\n",
            "Epoch 560/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 8.1309e-04 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9683\n",
            "Epoch 561/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.2801e-05 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9683\n",
            "Epoch 562/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.4886e-05 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9683\n",
            "Epoch 563/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.2575e-05 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9683\n",
            "Epoch 564/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7.0926e-06 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9683\n",
            "Epoch 565/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.5108e-06 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9683\n",
            "Epoch 566/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.4043e-06 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9683\n",
            "Epoch 567/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.5840e-06 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9683\n",
            "Epoch 568/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.3534e-06 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9683\n",
            "Epoch 569/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4527e-06 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9683\n",
            "Epoch 570/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.9861 - val_loss: 0.2036 - val_accuracy: 0.9762\n",
            "Epoch 571/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.2493e-04 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9683\n",
            "Epoch 572/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.3813e-05 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9683\n",
            "Epoch 573/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9.7323e-06 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9683\n",
            "Epoch 574/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6.1205e-06 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9683\n",
            "Epoch 575/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.7516e-06 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9683\n",
            "Epoch 576/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.7248e-06 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9683\n",
            "Epoch 577/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.0019e-06 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9683\n",
            "Epoch 578/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.6003e-06 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9683\n",
            "Epoch 579/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.1347e-06 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9683\n",
            "Epoch 580/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.2883e-06 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9683\n",
            "Epoch 581/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.2798e-06 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9683\n",
            "Epoch 582/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9.4325e-07 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9683\n",
            "Epoch 583/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.3158e-06 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9683\n",
            "Epoch 584/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.7309e-06 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9683\n",
            "Epoch 585/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.1254e-06 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9683\n",
            "Epoch 586/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.0854e-06 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9683\n",
            "Epoch 587/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7.6515e-07 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9683\n",
            "Epoch 588/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 8.1695e-07 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 0.9683\n",
            "Epoch 589/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0296 - accuracy: 0.9921 - val_loss: 0.2665 - val_accuracy: 0.9683\n",
            "Epoch 590/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 6.8314e-05 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9683\n",
            "Epoch 591/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9.0348e-06 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9683\n",
            "Epoch 592/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5.8093e-06 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9683\n",
            "Epoch 593/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.6748e-06 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9683\n",
            "Epoch 594/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.3240e-06 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9683\n",
            "Epoch 595/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.4761e-06 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9683\n",
            "Epoch 596/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.0095e-06 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.9683\n",
            "Epoch 597/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7.7367e-07 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9683\n",
            "Epoch 598/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7.6350e-07 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9683\n",
            "Epoch 599/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8.4225e-07 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9683\n",
            "Epoch 600/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 0.9980 - val_loss: 0.2650 - val_accuracy: 0.9683\n",
            "Epoch 601/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4.0245e-06 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9683\n",
            "Epoch 602/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.7403e-06 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9683\n",
            "Epoch 603/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.5890e-06 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9683\n",
            "Epoch 604/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4161e-06 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9683\n",
            "Epoch 605/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.3144e-06 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9683\n",
            "Epoch 606/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.1656e-06 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9683\n",
            "Epoch 607/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9.9080e-07 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9683\n",
            "Epoch 608/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 9.8274e-07 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9683\n",
            "Epoch 609/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.2668e-06 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9683\n",
            "Epoch 610/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6.0598e-07 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9683\n",
            "Epoch 611/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.3652e-06 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9683\n",
            "Epoch 612/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7.8005e-07 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9683\n",
            "Epoch 613/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5.8280e-07 - accuracy: 1.0000 - val_loss: 0.2501 - val_accuracy: 0.9683\n",
            "Epoch 614/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8.3516e-07 - accuracy: 1.0000 - val_loss: 0.2486 - val_accuracy: 0.9683\n",
            "Epoch 615/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5.3904e-07 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9683\n",
            "Epoch 616/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6.6203e-07 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9683\n",
            "Epoch 617/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8.6212e-07 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9683\n",
            "Epoch 618/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.3396e-06 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9683\n",
            "Epoch 619/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8.4107e-07 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9683\n",
            "Epoch 620/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 4.7494e-07 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9683\n",
            "Epoch 621/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 8.6590e-07 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9683\n",
            "Epoch 622/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0717 - accuracy: 0.9841 - val_loss: 0.2257 - val_accuracy: 0.9683\n",
            "Epoch 623/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.5961e-05 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9683\n",
            "Epoch 624/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.7886e-05 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9683\n",
            "Epoch 625/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.8832e-05 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9683\n",
            "Epoch 626/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.0295e-05 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9683\n",
            "Epoch 627/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 5.2437e-06 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9762\n",
            "Epoch 628/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3.1872e-06 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9762\n",
            "Epoch 629/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.3869e-06 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9683\n",
            "Epoch 630/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.4103e-06 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9683\n",
            "Epoch 631/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.1133e-06 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9762\n",
            "Epoch 632/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.1058 - accuracy: 0.9802 - val_loss: 0.2185 - val_accuracy: 0.9683\n",
            "Epoch 633/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 8.8468e-06 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9683\n",
            "Epoch 634/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 6.2560e-06 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9683\n",
            "Epoch 635/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 5.0418e-06 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9683\n",
            "Epoch 636/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 4.3507e-06 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9683\n",
            "Epoch 637/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.3401e-06 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9683\n",
            "Epoch 638/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.6519e-06 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9683\n",
            "Epoch 639/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 2.2727e-06 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9683\n",
            "Epoch 640/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.8181e-06 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9683\n",
            "Epoch 641/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.1111e-06 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9683\n",
            "Epoch 642/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 3.1260e-06 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9683\n",
            "Epoch 643/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.2450e-06 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9683\n",
            "Epoch 644/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.3151 - accuracy: 0.9782 - val_loss: 0.1836 - val_accuracy: 0.9683\n",
            "Epoch 645/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.8228e-05 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9683\n",
            "Epoch 646/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.1834e-05 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9683\n",
            "Epoch 647/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.4652e-05 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.9683\n",
            "Epoch 648/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 9.0997e-06 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9683\n",
            "Epoch 649/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 4.9862e-06 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9683\n",
            "Epoch 650/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.9323e-06 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9683\n",
            "Epoch 651/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.9792e-06 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9683\n",
            "Epoch 652/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4208e-06 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9683\n",
            "Epoch 653/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.5329e-06 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9683\n",
            "Epoch 654/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.3531e-06 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9683\n",
            "Epoch 655/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.3143e-06 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9683\n",
            "Epoch 656/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.1761 - accuracy: 0.9821 - val_loss: 0.2367 - val_accuracy: 0.9762\n",
            "Epoch 657/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9762\n",
            "Epoch 658/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 3.0742e-05 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9762\n",
            "Epoch 659/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.7162e-05 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9762\n",
            "Epoch 660/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.2738e-05 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9683\n",
            "Epoch 661/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 6.0424e-06 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9683\n",
            "Epoch 662/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 4.0016e-06 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9683\n",
            "Epoch 663/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 2.7139e-06 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9683\n",
            "Epoch 664/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.8994e-06 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 0.9683\n",
            "Epoch 665/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.4929e-06 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9683\n",
            "Epoch 666/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0100 - accuracy: 0.9960 - val_loss: 0.2451 - val_accuracy: 0.9683\n",
            "Epoch 667/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.7894e-06 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9683\n",
            "Epoch 668/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4808e-06 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9683\n",
            "Epoch 669/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.2763e-06 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9683\n",
            "Epoch 670/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.1992e-06 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9683\n",
            "Epoch 671/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.1055e-06 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9683\n",
            "Epoch 672/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.2325e-06 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.9683\n",
            "Epoch 673/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 9.5295e-07 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9683\n",
            "Epoch 674/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.1135e-06 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9683\n",
            "Epoch 675/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.0762e-06 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9683\n",
            "Epoch 676/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0795 - accuracy: 0.9821 - val_loss: 0.2047 - val_accuracy: 0.9683\n",
            "Epoch 677/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8.7607e-04 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9762\n",
            "Epoch 678/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.5380e-04 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9762\n",
            "Epoch 679/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4577e-05 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9762\n",
            "Epoch 680/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8.6179e-06 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9762\n",
            "Epoch 681/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.6800e-06 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9762\n",
            "Epoch 682/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.5295e-06 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9762\n",
            "Epoch 683/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.8815e-06 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9683\n",
            "Epoch 684/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.6481e-06 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9683\n",
            "Epoch 685/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4468e-06 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9683\n",
            "Epoch 686/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0160 - accuracy: 0.9960 - val_loss: 0.2472 - val_accuracy: 0.9683\n",
            "Epoch 687/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.1497e-04 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9683\n",
            "Epoch 688/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5.2058e-05 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9683\n",
            "Epoch 689/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.5253e-06 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9683\n",
            "Epoch 690/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.8136e-06 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9683\n",
            "Epoch 691/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.3330e-06 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9683\n",
            "Epoch 692/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.8805e-06 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9683\n",
            "Epoch 693/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.6814e-06 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9683\n",
            "Epoch 694/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.5099e-06 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9683\n",
            "Epoch 695/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0323 - accuracy: 0.9921 - val_loss: 0.2298 - val_accuracy: 0.9683\n",
            "Epoch 696/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.8569e-04 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9683\n",
            "Epoch 697/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.1837e-05 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9683\n",
            "Epoch 698/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7.9276e-06 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9683\n",
            "Epoch 699/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.8692e-06 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9683\n",
            "Epoch 700/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.2018e-06 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9683\n",
            "Epoch 701/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2.1651e-06 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9683\n",
            "Epoch 702/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.5516e-06 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9762\n",
            "Epoch 703/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.2493e-06 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.9683\n",
            "Epoch 704/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.1954e-06 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9762\n",
            "Epoch 705/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.0710e-06 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9683\n",
            "Epoch 706/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9.1866e-07 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9683\n",
            "Epoch 707/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9.3285e-07 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9683\n",
            "Epoch 708/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0727 - accuracy: 0.9841 - val_loss: 0.2289 - val_accuracy: 0.9683\n",
            "Epoch 709/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.2725e-04 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9683\n",
            "Epoch 710/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7.0916e-05 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9683\n",
            "Epoch 711/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.7695e-05 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9683\n",
            "Epoch 712/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.2280e-05 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 0.9683\n",
            "Epoch 713/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 5.8386e-06 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9683\n",
            "Epoch 714/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.2741e-06 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9683\n",
            "Epoch 715/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.8882e-06 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9683\n",
            "Epoch 716/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.2186e-06 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 0.9683\n",
            "Epoch 717/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 9.4042e-07 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9683\n",
            "Epoch 718/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8.4297e-07 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9683\n",
            "Epoch 719/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7.4221e-07 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9683\n",
            "Epoch 720/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 6.6558e-07 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9683\n",
            "Epoch 721/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7.0863e-07 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9683\n",
            "Epoch 722/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1212 - accuracy: 0.9841 - val_loss: 0.2089 - val_accuracy: 0.9683\n",
            "Epoch 723/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9683\n",
            "Epoch 724/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9.3795e-05 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9683\n",
            "Epoch 725/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.0819e-05 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9683\n",
            "Epoch 726/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.6157e-05 - accuracy: 1.0000 - val_loss: 0.1614 - val_accuracy: 0.9683\n",
            "Epoch 727/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9.1819e-06 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9683\n",
            "Epoch 728/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.6767e-06 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9683\n",
            "Epoch 729/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.8911e-06 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9683\n",
            "Epoch 730/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.8458e-06 - accuracy: 1.0000 - val_loss: 0.1749 - val_accuracy: 0.9683\n",
            "Epoch 731/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4927e-06 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9762\n",
            "Epoch 732/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.5731e-06 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.9683\n",
            "Epoch 733/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.0684e-06 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9683\n",
            "Epoch 734/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.2254e-06 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 0.9683\n",
            "Epoch 735/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 8.7135e-07 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9683\n",
            "Epoch 736/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0898 - accuracy: 0.9702 - val_loss: 0.2512 - val_accuracy: 0.9683\n",
            "Epoch 737/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7.3289e-05 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9683\n",
            "Epoch 738/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.1080e-05 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9683\n",
            "Epoch 739/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.0680e-05 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9683\n",
            "Epoch 740/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.0097e-05 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9683\n",
            "Epoch 741/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5.7552e-06 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9683\n",
            "Epoch 742/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.7421e-06 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9683\n",
            "Epoch 743/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.6915e-06 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9683\n",
            "Epoch 744/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.0863e-06 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9683\n",
            "Epoch 745/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 8.1127e-07 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9683\n",
            "Epoch 746/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7.3181e-07 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9683\n",
            "Epoch 747/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7.8195e-07 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9683\n",
            "Epoch 748/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7.8384e-07 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9683\n",
            "Epoch 749/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.1916e-06 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9683\n",
            "Epoch 750/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.1363 - val_accuracy: 0.9683\n",
            "Epoch 751/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 8.0961e-05 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9683\n",
            "Epoch 752/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4.2696e-05 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 0.9683\n",
            "Epoch 753/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2.3897e-05 - accuracy: 1.0000 - val_loss: 0.1464 - val_accuracy: 0.9683\n",
            "Epoch 754/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7.6668e-06 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9762\n",
            "Epoch 755/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.7424e-06 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9683\n",
            "Epoch 756/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.2572e-06 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9762\n",
            "Epoch 757/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.5674e-06 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9762\n",
            "Epoch 758/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.1202e-06 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9683\n",
            "Epoch 759/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.1225e-06 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9762\n",
            "Epoch 760/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.1334e-06 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9762\n",
            "Epoch 761/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4645e-06 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9762\n",
            "Epoch 762/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5.4708e-07 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9762\n",
            "Epoch 763/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7.9328e-07 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9683\n",
            "Epoch 764/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1593 - accuracy: 0.9881 - val_loss: 0.1505 - val_accuracy: 0.9683\n",
            "Epoch 765/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.8534e-05 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9762\n",
            "Epoch 766/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.3745e-05 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9762\n",
            "Epoch 767/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6.5322e-06 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9762\n",
            "Epoch 768/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.8718e-06 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.9762\n",
            "Epoch 769/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.4453e-06 - accuracy: 1.0000 - val_loss: 0.1649 - val_accuracy: 0.9762\n",
            "Epoch 770/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.7975e-06 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9762\n",
            "Epoch 771/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.4624e-06 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9762\n",
            "Epoch 772/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.3498e-06 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9762\n",
            "Epoch 773/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.1831e-06 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9762\n",
            "Epoch 774/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 8.5172e-07 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9683\n",
            "Epoch 775/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.2422e-06 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9762\n",
            "Epoch 776/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0536 - accuracy: 0.9861 - val_loss: 0.2226 - val_accuracy: 0.9762\n",
            "Epoch 777/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 4.7165e-04 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9762\n",
            "Epoch 778/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.0283e-04 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9762\n",
            "Epoch 779/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 2.0374e-06 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9762\n",
            "Epoch 780/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.6483e-06 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9762\n",
            "Epoch 781/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.3349e-06 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9762\n",
            "Epoch 782/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.0291e-06 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9762\n",
            "Epoch 783/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 8.2712e-07 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9683\n",
            "Epoch 784/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 7.0437e-07 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9683\n",
            "Epoch 785/1000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 6.3412e-07 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9683\n",
            "Epoch 786/1000\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 6.3980e-07 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9683\n",
            "Epoch 787/1000\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 6.1283e-07 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9683\n",
            "Epoch 788/1000\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 8.2617e-07 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9683\n",
            "Epoch 789/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 7.9566e-07 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9683\n",
            "Epoch 790/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4.3757e-07 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9683\n",
            "Epoch 791/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 4.5980e-07 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9683\n",
            "Epoch 792/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 4.2858e-07 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9683\n",
            "Epoch 793/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 3.6969e-07 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9683\n",
            "Epoch 794/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 4.3497e-07 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9683\n",
            "Epoch 795/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 4.1770e-07 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9762\n",
            "Epoch 796/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4.4727e-07 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9683\n",
            "Epoch 797/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3.4509e-07 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9683\n",
            "Epoch 798/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 3.1316e-07 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9683\n",
            "Epoch 799/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3.4935e-07 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9683\n",
            "Epoch 800/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3.1363e-07 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9683\n",
            "Epoch 801/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3.1221e-07 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9683\n",
            "Epoch 802/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.7673e-07 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9683\n",
            "Epoch 803/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 3.2664e-07 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9683\n",
            "Epoch 804/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 3.1008e-07 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9683\n",
            "Epoch 805/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 3.0677e-07 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9683\n",
            "Epoch 806/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3.1150e-07 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9762\n",
            "Epoch 807/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.2238e-07 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9683\n",
            "Epoch 808/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.8762e-07 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9683\n",
            "Epoch 809/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.0417e-07 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9683\n",
            "Epoch 810/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.7200e-07 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9683\n",
            "Epoch 811/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.0606e-07 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9683\n",
            "Epoch 812/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.1836e-07 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9683\n",
            "Epoch 813/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.8596e-07 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9683\n",
            "Epoch 814/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.6656e-07 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9683\n",
            "Epoch 815/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.5947e-07 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9683\n",
            "Epoch 816/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.6656e-07 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9683\n",
            "Epoch 817/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.4859e-07 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9683\n",
            "Epoch 818/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.4268e-07 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9683\n",
            "Epoch 819/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.8005e-07 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9683\n",
            "Epoch 820/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.6869e-07 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9683\n",
            "Epoch 821/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.3605e-07 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9683\n",
            "Epoch 822/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.5947e-07 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9683\n",
            "Epoch 823/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.7697e-07 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9683\n",
            "Epoch 824/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.6278e-07 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9683\n",
            "Epoch 825/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.4386e-07 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9683\n",
            "Epoch 826/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.4670e-07 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9683\n",
            "Epoch 827/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.5947e-07 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9683\n",
            "Epoch 828/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.3487e-07 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9683\n",
            "Epoch 829/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.4953e-07 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.9683\n",
            "Epoch 830/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.4504e-07 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9683\n",
            "Epoch 831/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.7390e-07 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9683\n",
            "Epoch 832/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.2872e-07 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9683\n",
            "Epoch 833/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.6893e-07 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9683\n",
            "Epoch 834/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.1595e-07 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9683\n",
            "Epoch 835/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.3227e-07 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9683\n",
            "Epoch 836/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.5734e-07 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9683\n",
            "Epoch 837/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.2541e-07 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.9683\n",
            "Epoch 838/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.2044e-07 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9683\n",
            "Epoch 839/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.1524e-07 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9683\n",
            "Epoch 840/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.2919e-07 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.9683\n",
            "Epoch 841/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.0862e-07 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9683\n",
            "Epoch 842/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.2399e-07 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9683\n",
            "Epoch 843/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.1737e-07 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9683\n",
            "Epoch 844/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.2328e-07 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9683\n",
            "Epoch 845/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2.1406e-07 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9683\n",
            "Epoch 846/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.1003e-07 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9683\n",
            "Epoch 847/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.0081e-07 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9683\n",
            "Epoch 848/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.1311e-07 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9683\n",
            "Epoch 849/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.2328e-07 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9683\n",
            "Epoch 850/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2.0389e-07 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9683\n",
            "Epoch 851/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.0389e-07 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9683\n",
            "Epoch 852/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.1145e-07 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9683\n",
            "Epoch 853/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.0601e-07 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9683\n",
            "Epoch 854/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.0459e-07 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9683\n",
            "Epoch 855/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.0412e-07 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9683\n",
            "Epoch 856/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.9774e-07 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9683\n",
            "Epoch 857/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.9915e-07 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9683\n",
            "Epoch 858/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.0578e-07 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9683\n",
            "Epoch 859/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.8686e-07 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9683\n",
            "Epoch 860/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.9277e-07 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9683\n",
            "Epoch 861/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.9797e-07 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9683\n",
            "Epoch 862/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.9774e-07 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9683\n",
            "Epoch 863/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.9703e-07 - accuracy: 1.0000 - val_loss: 0.1907 - val_accuracy: 0.9683\n",
            "Epoch 864/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.8898e-07 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9683\n",
            "Epoch 865/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.9230e-07 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9683\n",
            "Epoch 866/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.8591e-07 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9683\n",
            "Epoch 867/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.8047e-07 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9683\n",
            "Epoch 868/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.9111e-07 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9683\n",
            "Epoch 869/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.8993e-07 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9683\n",
            "Epoch 870/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.9300e-07 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9683\n",
            "Epoch 871/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.8662e-07 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9683\n",
            "Epoch 872/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.9371e-07 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9683\n",
            "Epoch 873/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.9088e-07 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9683\n",
            "Epoch 874/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.9679e-07 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9683\n",
            "Epoch 875/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.0081e-07 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9683\n",
            "Epoch 876/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.8094e-07 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9683\n",
            "Epoch 877/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.8638e-07 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9683\n",
            "Epoch 878/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.9135e-07 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9683\n",
            "Epoch 879/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.8544e-07 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9683\n",
            "Epoch 880/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.8473e-07 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9683\n",
            "Epoch 881/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.9230e-07 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9683\n",
            "Epoch 882/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.8307e-07 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9683\n",
            "Epoch 883/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.8260e-07 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9683\n",
            "Epoch 884/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.7952e-07 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9683\n",
            "Epoch 885/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.8756e-07 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9683\n",
            "Epoch 886/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.7621e-07 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9683\n",
            "Epoch 887/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.8118e-07 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9683\n",
            "Epoch 888/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.7645e-07 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9683\n",
            "Epoch 889/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.8922e-07 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9683\n",
            "Epoch 890/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.7456e-07 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9683\n",
            "Epoch 891/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.7858e-07 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9683\n",
            "Epoch 892/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.7101e-07 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9683\n",
            "Epoch 893/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.7124e-07 - accuracy: 1.0000 - val_loss: 0.1907 - val_accuracy: 0.9683\n",
            "Epoch 894/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.7219e-07 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9683\n",
            "Epoch 895/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.7881e-07 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9683\n",
            "Epoch 896/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.7124e-07 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9683\n",
            "Epoch 897/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.7976e-07 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9683\n",
            "Epoch 898/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.6959e-07 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9683\n",
            "Epoch 899/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.6793e-07 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9683\n",
            "Epoch 900/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.7148e-07 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9683\n",
            "Epoch 901/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.6959e-07 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9683\n",
            "Epoch 902/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.6841e-07 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9683\n",
            "Epoch 903/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.7077e-07 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9683\n",
            "Epoch 904/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.7408e-07 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9683\n",
            "Epoch 905/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.7054e-07 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9683\n",
            "Epoch 906/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.7243e-07 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9683\n",
            "Epoch 907/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.7290e-07 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9683\n",
            "Epoch 908/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.7479e-07 - accuracy: 1.0000 - val_loss: 0.1893 - val_accuracy: 0.9683\n",
            "Epoch 909/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.6510e-07 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9683\n",
            "Epoch 910/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.7124e-07 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9683\n",
            "Epoch 911/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.7266e-07 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9683\n",
            "Epoch 912/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.7668e-07 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9683\n",
            "Epoch 913/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.5753e-07 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9683\n",
            "Epoch 914/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.7219e-07 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9683\n",
            "Epoch 915/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.7030e-07 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9683\n",
            "Epoch 916/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.6533e-07 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9683\n",
            "Epoch 917/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.6746e-07 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9683\n",
            "Epoch 918/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.6084e-07 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9683\n",
            "Epoch 919/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.6533e-07 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9683\n",
            "Epoch 920/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.5611e-07 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9683\n",
            "Epoch 921/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.5540e-07 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9683\n",
            "Epoch 922/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.6226e-07 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9683\n",
            "Epoch 923/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.5658e-07 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9683\n",
            "Epoch 924/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.6675e-07 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9683\n",
            "Epoch 925/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.6107e-07 - accuracy: 1.0000 - val_loss: 0.1893 - val_accuracy: 0.9683\n",
            "Epoch 926/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.6155e-07 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9683\n",
            "Epoch 927/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.6060e-07 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9683\n",
            "Epoch 928/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.5776e-07 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9683\n",
            "Epoch 929/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.6391e-07 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9683\n",
            "Epoch 930/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.5611e-07 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9683\n",
            "Epoch 931/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.5398e-07 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9683\n",
            "Epoch 932/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.6249e-07 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9683\n",
            "Epoch 933/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.5800e-07 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9683\n",
            "Epoch 934/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.6297e-07 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9683\n",
            "Epoch 935/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.6202e-07 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9683\n",
            "Epoch 936/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.5800e-07 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9683\n",
            "Epoch 937/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.5611e-07 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9683\n",
            "Epoch 938/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.4877e-07 - accuracy: 1.0000 - val_loss: 0.1893 - val_accuracy: 0.9683\n",
            "Epoch 939/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.5398e-07 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9683\n",
            "Epoch 940/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.5398e-07 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9683\n",
            "Epoch 941/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.5280e-07 - accuracy: 1.0000 - val_loss: 0.1907 - val_accuracy: 0.9683\n",
            "Epoch 942/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.5895e-07 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.9683\n",
            "Epoch 943/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.5019e-07 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9683\n",
            "Epoch 944/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.5327e-07 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9683\n",
            "Epoch 945/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.5327e-07 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9683\n",
            "Epoch 946/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.5209e-07 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9683\n",
            "Epoch 947/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.5303e-07 - accuracy: 1.0000 - val_loss: 0.1907 - val_accuracy: 0.9683\n",
            "Epoch 948/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.4948e-07 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9683\n",
            "Epoch 949/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.5232e-07 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9683\n",
            "Epoch 950/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.5161e-07 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9683\n",
            "Epoch 951/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.5705e-07 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9683\n",
            "Epoch 952/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.5256e-07 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9683\n",
            "Epoch 953/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.5043e-07 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9683\n",
            "Epoch 954/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.4996e-07 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9683\n",
            "Epoch 955/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.4499e-07 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9683\n",
            "Epoch 956/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4404e-07 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9683\n",
            "Epoch 957/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.5043e-07 - accuracy: 1.0000 - val_loss: 0.1907 - val_accuracy: 0.9683\n",
            "Epoch 958/1000\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.4523e-07 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9683\n",
            "Epoch 959/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4641e-07 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9683\n",
            "Epoch 960/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4215e-07 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9683\n",
            "Epoch 961/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4665e-07 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9683\n",
            "Epoch 962/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.5043e-07 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9683\n",
            "Epoch 963/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4263e-07 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9683\n",
            "Epoch 964/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4263e-07 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9683\n",
            "Epoch 965/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.5043e-07 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9683\n",
            "Epoch 966/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4712e-07 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9683\n",
            "Epoch 967/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4996e-07 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9683\n",
            "Epoch 968/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4570e-07 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9683\n",
            "Epoch 969/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4617e-07 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9683\n",
            "Epoch 970/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4594e-07 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9683\n",
            "Epoch 971/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4192e-07 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9683\n",
            "Epoch 972/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4286e-07 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9683\n",
            "Epoch 973/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4452e-07 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9683\n",
            "Epoch 974/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4121e-07 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9683\n",
            "Epoch 975/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4026e-07 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9683\n",
            "Epoch 976/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4215e-07 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9683\n",
            "Epoch 977/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4026e-07 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9683\n",
            "Epoch 978/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4570e-07 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9683\n",
            "Epoch 979/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4168e-07 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9683\n",
            "Epoch 980/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4121e-07 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9683\n",
            "Epoch 981/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.3577e-07 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9683\n",
            "Epoch 982/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4783e-07 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9683\n",
            "Epoch 983/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4097e-07 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9683\n",
            "Epoch 984/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4097e-07 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9683\n",
            "Epoch 985/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4050e-07 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9683\n",
            "Epoch 986/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4002e-07 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9683\n",
            "Epoch 987/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.3955e-07 - accuracy: 1.0000 - val_loss: 0.1907 - val_accuracy: 0.9683\n",
            "Epoch 988/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4002e-07 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9683\n",
            "Epoch 989/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.3931e-07 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9683\n",
            "Epoch 990/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.3151e-07 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9683\n",
            "Epoch 991/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.3482e-07 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9683\n",
            "Epoch 992/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.3719e-07 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9683\n",
            "Epoch 993/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4073e-07 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9683\n",
            "Epoch 994/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.4310e-07 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9683\n",
            "Epoch 995/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.3624e-07 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9683\n",
            "Epoch 996/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.3198e-07 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9683\n",
            "Epoch 997/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.4215e-07 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9683\n",
            "Epoch 998/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.3553e-07 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9683\n",
            "Epoch 999/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.3364e-07 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9683\n",
            "Epoch 1000/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.3742e-07 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9683\n",
            "Train Accuracy: 100.00% , Test Accuracy: 96.83% \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input data (you should replace this with your actual input data)\n",
        "new_data = X_test\n",
        "expected = Y_test\n",
        "expected = expected.to_numpy()\n",
        "# Make predictions\n",
        "predicted_stress_level = model.predict(X_test)\n",
        "predicted_stress_level = np.argmax(predicted_stress_level, axis=1)\n",
        "# Print the predicted stress level\n",
        "issues = 0\n",
        "size = len(X_test)\n",
        "for i in range(0, size):\n",
        "  if predicted_stress_level[i] != expected[i]:\n",
        "    issues += 1\n",
        "    print(\"Sample\", i+1, \"- Predicted Stress Level:\", predicted_stress_level[i], \"Expected:\", expected[i])\n",
        "print(\"Issues: {} out of {}\".format(issues,size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIUeTsKKv3zn",
        "outputId": "46503710-d6d3-46a6-8b56-9e28ae7a395a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 6ms/step\n",
            "Sample 21 - Predicted Stress Level: 1 Expected: 0\n",
            "Sample 64 - Predicted Stress Level: 2 Expected: 3\n",
            "Sample 86 - Predicted Stress Level: 3 Expected: 4\n",
            "Sample 88 - Predicted Stress Level: 3 Expected: 2\n",
            "Issues: 4 out of 126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i WANT A CONFUSIUON MATRIX FOR y TEST AND Y PRED\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convert the predictions to class labels\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Create the confusion matrix\n",
        "cm = confusion_matrix(Y_test, y_pred_classes)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(cm)\n",
        "len(Y_test), len(X_test)"
      ],
      "metadata": {
        "id": "FF_fOHNZo0I_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "933c944b-bcd9-43c7-b88c-4517fd1f3486"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n",
            "[[24  1  0  0  0]\n",
            " [ 0 23  0  0  0]\n",
            " [ 0  0 28  1  0]\n",
            " [ 0  0  1 21  0]\n",
            " [ 0  0  0  1 26]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(126, 126)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4aPRiHTO9aiN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}