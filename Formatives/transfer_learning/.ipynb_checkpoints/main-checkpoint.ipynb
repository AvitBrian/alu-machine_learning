{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea93e91d-4363-4fc4-8777-a3d34ee41013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 187 images belonging to 6 classes.\n",
      "6\n",
      "Found 18 images belonging to 6 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 10s/step - accuracy: 0.1952 - loss: 2.2091 - val_accuracy: 0.1667 - val_loss: 1.8250\n",
      "Epoch 2/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 10s/step - accuracy: 0.3791 - loss: 1.6643 - val_accuracy: 0.5000 - val_loss: 1.4364\n",
      "Epoch 3/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 11s/step - accuracy: 0.4196 - loss: 1.3996 - val_accuracy: 0.6111 - val_loss: 1.3623\n",
      "Epoch 4/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 10s/step - accuracy: 0.5249 - loss: 1.1585 - val_accuracy: 0.4444 - val_loss: 1.3351\n",
      "Epoch 5/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 10s/step - accuracy: 0.5560 - loss: 1.0378 - val_accuracy: 0.5000 - val_loss: 1.2642\n",
      "Epoch 6/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 10s/step - accuracy: 0.7431 - loss: 0.7699 - val_accuracy: 0.6667 - val_loss: 1.0746\n",
      "Epoch 7/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 10s/step - accuracy: 0.7505 - loss: 0.7806 - val_accuracy: 0.6111 - val_loss: 1.0600\n",
      "Epoch 8/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 10s/step - accuracy: 0.7927 - loss: 0.6572 - val_accuracy: 0.5556 - val_loss: 1.0120\n",
      "Epoch 9/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 10s/step - accuracy: 0.8458 - loss: 0.5517 - val_accuracy: 0.6111 - val_loss: 0.9720\n",
      "Epoch 10/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 10s/step - accuracy: 0.8937 - loss: 0.4021 - val_accuracy: 0.6111 - val_loss: 1.0939\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define relevant classes (e.g., for animals that interact with crops/livestock)\n",
    "animal_classes = [\n",
    "    'n01560419',  # Crow\n",
    "    'n01817953',  # Pigeon\n",
    "    'n01558993',  # European Starling\n",
    "    'n01532829',  # Sparrow\n",
    "    'n01843383',  # Hornbill\n",
    "    'n01855672'   # Bee-eater\n",
    "]\n",
    "\n",
    "# Directory paths to your ImageNet dataset\n",
    "train_dir = 'data/train'\n",
    "val_dir = 'data/val'\n",
    "\n",
    "\n",
    "# Define ImageDataGenerators\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "# Load and preprocess the data\n",
    "train_data = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "    classes=[str(cls) for cls in animal_classes]\n",
    ")\n",
    "\n",
    "print(len(train_data))\n",
    "val_data = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),  # ImageNet standard size\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "    classes=[str(cls) for cls in animal_classes]\n",
    ")\n",
    "\n",
    "# Load the pre-trained model (VGG16) without the top layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(len(animal_classes), activation='softmax')(x)  # Update to the number of classes\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data, epochs=10, validation_data=val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1188a587-7065-4898-b193-8ceba9d2cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_image(img_path):\n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = img_array / 255.0  # Normalize\n",
    "    return img_array\n",
    "\n",
    "def predict_image_class(model, img_path):\n",
    "    # Load and preprocess the image\n",
    "    img_array = load_and_preprocess_image(img_path)\n",
    "    \n",
    "    # Predict the class\n",
    "    predictions = model.predict(img_array)\n",
    "    class_index = np.argmax(predictions[0])\n",
    "    \n",
    "    return class_index, predictions[0][class_index]\n",
    "\n",
    "# Example usage\n",
    "img_path = 'path/to/your/image.jpg'\n",
    "class_index, probability = predict_image_class(model, img_path)\n",
    "print(f\"Predicted Class Index: {class_index}, Probability: {probability}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
